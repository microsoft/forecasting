{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters of LightGBM Model with AML SDK and HyperDrive\n",
    "\n",
    "This notebook performs hyperparameter tuning of LightGBM model with AML SDK and HyperDrive. It selects the best model by cross validation using the training data in the first forecast round. Specifically, it splits the training data into sub-training data and validation data. Then, it trains LightGBM models with different sets of hyperparameters using the sub-training data and evaluate the accuracy of each model with the validation data. The set of hyperparameters which yield the best validation accuracy will be used to train models and forecast sales across all 12 forecast rounds.\n",
    "\n",
    "## Prerequisites\n",
    "To run this notebook, you need to install AML SDK and its widget extension in your environment by running the following commands in a terminal. Before running the commands, you need to activate your environment by executing `source activate <your env>` in a Linux VM.   \n",
    "`pip3 install --upgrade azureml-sdk[notebooks,automl]`  \n",
    "`jupyter nbextension install --py --user azureml.widgets`  \n",
    "`jupyter nbextension enable --py --user azureml.widgets`  \n",
    "\n",
    "To add the environment to your Jupyter kernels, you can do `python3 -m ipykernel install --name <your env>`. Besides, you need to create an Azure ML workspace and download its configuration file (`config.json`) by following the [configuration.ipynb](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "# Opt-in diagnostics for better experience of future releases\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace & Create an Azure ML Experiment\n",
    "\n",
    "Initialize a [Machine Learning Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the workspace you created in the Prerequisites step. `Workspace.from_config()` below creates a workspace object from the details stored in `config.json` that you have downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tune_lgbm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Script Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Configure local, user managed environment\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "run_config_user_managed.environment.python.interpreter_path = '/usr/bin/python3.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "# Please update data-folder argument before submitting the job\n",
    "src = ScriptRunConfig(source_directory='./', \n",
    "                      script='train_validate.py', \n",
    "                      arguments=['--data-folder', \n",
    "                                 '/home/chenhui/TSPerf/retail_sales/OrangeJuice_Pt_3Weeks_Weekly/data/', \n",
    "                                 '--bagging-fraction', '0.8'],\n",
    "                      run_config=run_config_user_managed)\n",
    "run_local = exp.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check job status\n",
    "run_local.get_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "while(run_local.get_status() != 'Completed'): {}\n",
    "run_local.get_details()\n",
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script on Remote Compute Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CPU cluster as compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your cluster\n",
    "cluster_name = \"cpucluster\"\n",
    "\n",
    "try:\n",
    "    # Look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    if type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target {}.'.format(cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not an AML Compute target. Please choose a different name.'.format(cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_D14_v2\", # CPU-based VM\n",
    "                                                            #vm_priority='lowpriority', # optional\n",
    "                                                            min_nodes=0, \n",
    "                                                            max_nodes=4,\n",
    "                                                            idle_seconds_before_scaledown=3600)\n",
    "    # Create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    # Can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    # Get a detailed status for the current cluster. \n",
    "    print(compute_target.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have created the compute target, you should see one entry named 'cpucluster' of type AmlCompute \n",
    "# in the workspace's compute_targets property.\n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'numpy', 'scipy', 'scikit-learn', 'lightgbm', 'joblib'],\n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to default datastore\n",
    "\n",
    "Upload the Orange Juice dataset to the workspace's default datastore, which will later be mounted on the cluster for model training and validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_on_datastore = 'data'\n",
    "ds.upload(src_dir='../../data', target_path=path_on_datastore, overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = ds.path(path_on_datastore)\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator\n",
    "Next, we will check if the remote compute target is successfully created by submitting a job to the target. This compute target will be used by HyperDrive to tune the hyperparameters later. You may skip this part of code and directly jump into [Tune Hyperparameters using HyperDrive](#tune-hyperparameters-using-hyperdrive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "script_params = {\n",
    "    '--data-folder': ds_data.as_mount(),\n",
    "    '--bagging-fraction': 0.8\n",
    "}\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validate.py',\n",
    "                environment_definition=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to compute target\n",
    "run_remote = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run_remote).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_remote.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metric value after the job finishes  \n",
    "while(run_remote.get_status() != 'Completed'): {}\n",
    "run_remote.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='tune-hyperparameters-using-hyperdrive'></a>\n",
    "## Tune Hyperparameters using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "script_folder = './'\n",
    "script_params = {\n",
    "    '--data-folder': ds_data.as_mount()                                                 \n",
    "}\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validate.py',\n",
    "                environment_definition=env)\n",
    "ps = BayesianParameterSampling({\n",
    "    '--num-leaves': quniform(8, 128, 1),\n",
    "    '--min-data-in-leaf': quniform(20, 500, 10),\n",
    "    '--learning-rate': choice(1e-4, 1e-3, 5e-3, 1e-2, 1.5e-2, 2e-2, 3e-2, 5e-2, 1e-1),\n",
    "    '--feature-fraction': uniform(0.2, 1), \n",
    "    '--bagging-fraction': uniform(0.1, 1), \n",
    "    '--bagging-freq': quniform(1, 20, 1), \n",
    "    '--max-rounds': quniform(50, 2000, 10),\n",
    "    '--max-lag': quniform(3, 40, 1), \n",
    "    '--window-size': quniform(3, 40, 1), \n",
    "})\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='MAPE', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=200,\n",
    "                          max_concurrent_runs=4)\n",
    "htr = exp.submit(config=htc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(htr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(htr.get_status() != 'Completed'): {}\n",
    "htr.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = htr.get_best_run_by_primary_metric()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "print(parameter_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
