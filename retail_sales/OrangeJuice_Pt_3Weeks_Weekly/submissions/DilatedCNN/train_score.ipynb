{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tesla K80', 'Tesla K80']\n",
      "CUDA Version 9.0.176\n"
     ]
    }
   ],
   "source": [
    "import os, sys, subprocess\n",
    "\n",
    "def get_gpu_name():\n",
    "    try:\n",
    "        out_str = subprocess.run([\"nvidia-smi\", \"--query-gpu=gpu_name\", \"--format=csv\"], stdout=subprocess.PIPE).stdout\n",
    "        out_list = out_str.decode(\"utf-8\").split('\\n')\n",
    "        out_list = out_list[1:-1]\n",
    "        return out_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def get_cuda_version():\n",
    "    \"\"\"Get CUDA version\"\"\"\n",
    "    if sys.platform == 'win32':\n",
    "        raise NotImplementedError(\"Implement this!\")\n",
    "        # This breaks on linux:\n",
    "        #cuda=!ls \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\"\n",
    "        #path = \"C:\\\\Program Files\\\\NVIDIA GPU Computing Toolkit\\\\CUDA\\\\\" + str(cuda[0]) +\"\\\\version.txt\"\n",
    "    elif sys.platform == 'linux' or sys.platform == 'darwin':\n",
    "        path = '/usr/local/cuda/version.txt'\n",
    "    else:\n",
    "        raise ValueError(\"Not in Windows, Linux or Mac\")\n",
    "    if os.path.isfile(path):\n",
    "        with open(path, 'r') as f:\n",
    "            data = f.read().replace('\\n','')\n",
    "        return data\n",
    "    else:\n",
    "        return \"No CUDA in this machine\"\n",
    "    \n",
    "print(get_gpu_name())\n",
    "print(get_cuda_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import keras\n",
    "import datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import * \n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append TSPerf path to sys.path\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "tsperf_dir = os.path.dirname(os.path.dirname(os.path.dirname(nb_dir)))\n",
    "if tsperf_dir not in sys.path:\n",
    "    sys.path.append(tsperf_dir)\n",
    "\n",
    "from common.metrics import MAPE\n",
    "import retail_sales.OrangeJuice_Pt_3Weeks_Weekly.common.benchmark_settings as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "DATA_DIR = '../../data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# Data parameters\n",
    "MAX_STORE_ID = 137\n",
    "MAX_BRAND_ID = 11\n",
    "\n",
    "# Parameters of the model\n",
    "PRED_HORIZON = 3\n",
    "PRED_STEPS = 2\n",
    "SEQ_LEN = 8\n",
    "DYNAMIC_FEATURES = ['deal', 'feat']\n",
    "STATIC_FEATURES = ['store', 'brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_cartesian_product(dict_in):\n",
    "    \"\"\"Generate a Pandas dataframe from Cartesian product of lists.\n",
    "    \n",
    "    Args: \n",
    "        dict_in (Dictionary): Dictionary containing multiple lists\n",
    "        \n",
    "    Returns:\n",
    "        df (Dataframe): Dataframe corresponding to the Caresian product of the lists\n",
    "    \"\"\"\n",
    "    from collections import OrderedDict\n",
    "    from itertools import product\n",
    "    od = OrderedDict(sorted(dict_in.items()))\n",
    "    cart = list(product(*od.values()))\n",
    "    df = pd.DataFrame(cart, columns=od.keys())\n",
    "    return df\n",
    "\n",
    "def gen_sequence(df, seq_len, seq_cols, start_timestep=0, end_timestep=None):\n",
    "    \"\"\"Reshape features into an array of dimension (time steps, features).  \n",
    "    \n",
    "    Args:\n",
    "        df (Dataframe): Time series data of a specific (store, brand) combination\n",
    "        seq_len (Integer): The number of previous time series values to use as input features\n",
    "        seq_cols (List): A list of names of the feature columns \n",
    "        start_timestep (Integer): First time step you can use to create feature sequences\n",
    "        end_timestep (Integer): Last time step you can use to create feature sequences\n",
    "        \n",
    "    Returns:\n",
    "        A generator object for iterating all the feature sequences\n",
    "    \"\"\"\n",
    "    data_array = df[seq_cols].values\n",
    "    if end_timestep is None:\n",
    "        end_timestep = df.shape[0]\n",
    "    for start, stop in zip(range(start_timestep, end_timestep-seq_len+2), range(start_timestep+seq_len, end_timestep+2)):\n",
    "        yield data_array[start:stop, :]\n",
    "\n",
    "\n",
    "def gen_sequence_array(df_all, seq_len, seq_cols, start_timestep=0, end_timestep=None):\n",
    "    \"\"\"Combine feature sequences for all the combinations of (store, brand) into an 3d array.\n",
    "    \n",
    "    Args:\n",
    "        df_all (Dataframe): Time series data of all stores and brands\n",
    "        seq_len (Integer): The number of previous time series values to use as input features\n",
    "        seq_cols (List): A list of names of the feature columns \n",
    "        start_timestep (Integer): First time step you can use to create feature sequences\n",
    "        end_timestep (Integer): Last time step you can use to create feature sequences\n",
    "        \n",
    "    Returns:\n",
    "        seq_array (Numpy Array): An array of the feature sequences of all stores and brands    \n",
    "    \"\"\"\n",
    "    seq_gen = (list(gen_sequence(df_all[(df_all['store']==cur_store) & (df_all['brand']==cur_brand)], \\\n",
    "                                 seq_len, seq_cols, start_timestep, end_timestep)) \\\n",
    "              for cur_store, cur_brand in itertools.product(df_all['store'].unique(), df_all['brand'].unique()))\n",
    "    seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "    return seq_array\n",
    "\n",
    "def static_feature_array(df_all, total_timesteps, seq_cols):\n",
    "    \"\"\"Generate an arary which encodes all the static features.\n",
    "    \n",
    "    Args:\n",
    "        df_all (Dataframe): Time series data of all stores and brands\n",
    "        total_timesteps (Integer): Total number of training samples for each store and brand\n",
    "        seq_cols (List): A list of names of the static feature columns (e.g., store index)\n",
    "        \n",
    "    Return:\n",
    "        fea_array (Numpy Array): An array of static features of all stores and brands\n",
    "    \"\"\"\n",
    "    fea_df = data_filled.groupby(['store', 'brand']). \\\n",
    "                         apply(lambda x: x.iloc[:total_timesteps,:]). \\\n",
    "                         reset_index(drop=True)\n",
    "    fea_array = fea_df[seq_cols].values\n",
    "    return fea_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Round 1 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6204\n",
      "\n",
      "   brand  store  week  constant    price1    price2    price3    price4  \\\n",
      "0      1      2    40       1.0  0.060469  0.060497  0.042031  0.029531   \n",
      "1      1      2    41       1.0  0.060469  0.060497  0.042031  0.029531   \n",
      "2      1      2    42       1.0  0.060469  0.060497  0.042031  0.029531   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984   1.0   \n",
      "1  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984   1.0   \n",
      "2  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984   1.0   \n",
      "\n",
      "   feat     profit    move  \n",
      "0   0.0  37.992326  8256.0  \n",
      "1   0.0  37.992326  8256.0  \n",
      "2   0.0  37.992326  8256.0  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "r = 0\n",
    "print('---- Round ' + str(r+1) + ' ----')\n",
    "train_df = pd.read_csv(os.path.join(TRAIN_DIR, 'train_round_'+str(r+1)+'.csv'))\n",
    "train_df['move'] = train_df['logmove'].apply(lambda x: round(math.exp(x)))\n",
    "train_df.drop('logmove', axis=1, inplace=True)\n",
    "print(train_df.head(3))\n",
    "print('')\n",
    "# Fill missing values\n",
    "store_list = train_df['store'].unique()\n",
    "brand_list = train_df['brand'].unique()\n",
    "week_list = range(bs.TRAIN_START_WEEK, bs.TEST_END_WEEK_LIST[r]+1)\n",
    "d = {'store': store_list,\n",
    "     'brand': brand_list,\n",
    "     'week': week_list}        \n",
    "data_grid = df_from_cartesian_product(d)\n",
    "data_filled = pd.merge(data_grid, train_df, how='left', \n",
    "                        on=['store', 'brand', 'week'])\n",
    "print('Number of missing rows is {}'.format(data_filled[data_filled.isnull().any(axis=1)].shape[0]))\n",
    "print('')\n",
    "data_filled = data_filled.groupby(['store', 'brand']). \\\n",
    "                          apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "print(data_filled.head(3))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>constant</th>\n",
       "      <th>deal</th>\n",
       "      <th>feat</th>\n",
       "      <th>move</th>\n",
       "      <th>price1</th>\n",
       "      <th>price10</th>\n",
       "      <th>price11</th>\n",
       "      <th>price2</th>\n",
       "      <th>price3</th>\n",
       "      <th>price4</th>\n",
       "      <th>price5</th>\n",
       "      <th>price6</th>\n",
       "      <th>price7</th>\n",
       "      <th>price8</th>\n",
       "      <th>price9</th>\n",
       "      <th>profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.38567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.38567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.38567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.38567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.493088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>0.686433</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.485356</td>\n",
       "      <td>0.38567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   constant  deal  feat      move  price1   price10  price11    price2  \\\n",
       "0       0.0   1.0   0.0  0.011436     1.0  0.493088      1.0  0.993939   \n",
       "1       0.0   1.0   0.0  0.011436     1.0  0.493088      1.0  0.993939   \n",
       "2       0.0   1.0   0.0  0.011436     1.0  0.493088      1.0  0.993939   \n",
       "3       0.0   1.0   0.0  0.011436     1.0  0.493088      1.0  0.993939   \n",
       "4       0.0   1.0   0.0  0.011436     1.0  0.493088      1.0  0.993939   \n",
       "\n",
       "     price3    price4  price5  price6    price7    price8    price9   profit  \n",
       "0  0.686433  0.434783     1.0     1.0  0.731481  0.977528  0.485356  0.38567  \n",
       "1  0.686433  0.434783     1.0     1.0  0.731481  0.977528  0.485356  0.38567  \n",
       "2  0.686433  0.434783     1.0     1.0  0.731481  0.977528  0.485356  0.38567  \n",
       "3  0.686433  0.434783     1.0     1.0  0.731481  0.977528  0.485356  0.38567  \n",
       "4  0.686433  0.434783     1.0     1.0  0.731481  0.977528  0.485356  0.38567  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the dataframe of features\n",
    "cols_normalize = data_filled.columns.difference(['store','brand','week'])\n",
    "min_max_scaler = MinMaxScaler()\n",
    "data_filled_scaled = pd.DataFrame(min_max_scaler.fit_transform(data_filled[cols_normalize]), \n",
    "                                  columns=cols_normalize, \n",
    "                                  index=data_filled.index)\n",
    "data_filled_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 19)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub = data_filled[(data_filled.brand==1) & (data_filled.store==2)]\n",
    "data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78518, 8, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_timestep = 0\n",
    "end_timestep = bs.TRAIN_END_WEEK_LIST[r]-bs.TRAIN_START_WEEK-PRED_HORIZON+1\n",
    "\n",
    "train_input1 = gen_sequence_array(data_filled, SEQ_LEN, ['move'], start_timestep, end_timestep)\n",
    "\n",
    "train_input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78518, 8, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_timestep = PRED_HORIZON\n",
    "end_timestep = bs.TRAIN_END_WEEK_LIST[r]-bs.TRAIN_START_WEEK+1\n",
    "\n",
    "train_input2 = gen_sequence_array(data_filled, SEQ_LEN, DYNAMIC_FEATURES, start_timestep, end_timestep)\n",
    "\n",
    "train_input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78518, 8, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input = np.concatenate((train_input1, train_input2), axis=2)\n",
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78518, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_output\n",
    "start_timestep = SEQ_LEN+1\n",
    "end_timestep = bs.TRAIN_END_WEEK_LIST[r]-bs.TRAIN_START_WEEK+1\n",
    "train_output = gen_sequence_array(data_filled, PRED_STEPS, ['move'], start_timestep, end_timestep)\n",
    "train_output = np.squeeze(train_output)\n",
    "train_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       ...,\n",
       "       [1, 2],\n",
       "       [1, 2],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_col = np.full([train_input1.shape[0],1], 1)\n",
    "brand_col = np.full([train_input1.shape[0],1], 2)\n",
    "np.concatenate((store_col, brand_col), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.73084502,\n",
       "        0.11508554],\n",
       "       [0.        , 0.        , 0.01020408, ..., 0.        , 0.73084502,\n",
       "        0.11508554],\n",
       "       [0.        , 0.        , 0.02040816, ..., 0.        , 0.73084502,\n",
       "        0.11508554],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.97959184, ..., 0.        , 0.3278259 ,\n",
       "        0.21617418],\n",
       "       [0.        , 0.        , 0.98979592, ..., 0.        , 0.3278259 ,\n",
       "        0.21617418],\n",
       "       [0.        , 0.        , 1.        , ..., 0.        , 0.3278259 ,\n",
       "        0.21617418]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_sub)\n",
    "data_sub_scaled = scaler.transform(data_sub)\n",
    "data_sub_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "       1.        , 0.62921348, 0.25477707, 1.        , 1.        ,\n",
       "       0.70103093, 0.97435897, 0.41148325, 0.35294118, 1.        ,\n",
       "       1.        , 0.        , 0.73084502, 0.11508554])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sub_scaled[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = bs.TRAIN_END_WEEK_LIST[r]-bs.TRAIN_START_WEEK-SEQ_LEN-PRED_HORIZON+2\n",
    "train_input2 = static_feature_array(data_filled, total_timesteps, ['store', 'brand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78518, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "def create_dcnn_model(seq_len, kernel_size=2, n_filters=4, n_input_series=1, n_outputs=1):\n",
    "    # Sequential input\n",
    "    seq_in = Input(shape=(seq_len, n_input_series))\n",
    "    # Categorical input\n",
    "    cat_fea_in = Input(shape=(2,), dtype='uint8')\n",
    "    store_id = Lambda(lambda x: x[:, 0, None])(cat_fea_in)\n",
    "    brand_id = Lambda(lambda x: x[:, 1, None])(cat_fea_in)\n",
    "    store_embed = Embedding(MAX_STORE_ID+1, 7, input_length=1)(store_id)\n",
    "    brand_embed = Embedding(MAX_BRAND_ID+1, 4, input_length=1)(brand_id)\n",
    "    \n",
    "    # Dilated convolutional layers\n",
    "    c1 = Conv1D(filters=n_filters, kernel_size=kernel_size, dilation_rate=1, \n",
    "                padding='causal', activation='relu')(seq_in)\n",
    "    c2 = Conv1D(filters=n_filters, kernel_size=kernel_size, dilation_rate=2, \n",
    "                padding='causal', activation='relu')(c1)\n",
    "    c3 = Conv1D(filters=n_filters, kernel_size=kernel_size, dilation_rate=4, \n",
    "                padding='causal', activation='relu')(c2)\n",
    "    # Skip connections\n",
    "    c4 = concatenate([c1, c3])\n",
    "    # Output of convolutional layers \n",
    "    conv_out = Conv1D(8, 1, activation='relu')(c4)\n",
    "    conv_out = Dropout(0.25)(conv_out)\n",
    "    conv_out = Flatten()(conv_out)\n",
    "    \n",
    "    # Concatenate with categorical features\n",
    "    x = concatenate([conv_out, Flatten()(store_embed), Flatten()(brand_embed)])\n",
    "    #x = BatchNormalization()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    output = Dense(n_outputs, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=[seq_in, cat_fea_in], outputs=output)\n",
    "    adam = optimizers.Adam(lr=0.01)\n",
    "    model.compile(loss='mse', optimizer=adam, metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 8, 1)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 8, 4)         12          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8, 4)         36          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 8, 4)         36          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8)         0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 8, 8)         72          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 8, 8)         0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 7)         966         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 4)         48          lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 64)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 7)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 4)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 75)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           4864        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2)            66          dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 8,180\n",
      "Trainable params: 8,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_dcnn_model(seq_len=SEQ_LEN, n_outputs=PRED_STEPS)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit([train_input1, train_input2], train_output, epochs=2, batch_size=2, validation_data=([train_input1, train_input2], train_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9905.389"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(train_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "try:\n",
    "    model = multi_gpu_model(model)\n",
    "    print(\"Training using multiple GPUs..\")\n",
    "except:\n",
    "    print(\"Training using single GPU or CPU..\")\n",
    "\n",
    "start_time = time.time()\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "model.compile(loss='mse', optimizer=adam, metrics=['mae'])\n",
    "model.fit([train_input1, train_input2], train_output, epochs=2, batch_size=2, validation_data=([train_input1, train_input2], train_output))\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = multi_gpu_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
