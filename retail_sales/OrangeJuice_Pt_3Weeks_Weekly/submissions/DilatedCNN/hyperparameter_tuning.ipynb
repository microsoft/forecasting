{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of Dilated CNN Models with AML SDK and HyperDrive\n",
    "\n",
    "This notebook performs hyperparameter tuning of Dilated CNN models with AML SDK and HyperDrive. It selects the best model by cross validation using the training data in the first forecast round. Specifically, it splits the training data into sub-training data and validation data. Then, it trains Dilated CNN models with different sets of hyperparameters using the sub-training data and evaluate the accuracy of each model with the validation data. The set of hyperparameters which yield the best validation accuracy will be used to train models and forecast sales across all 12 forecast rounds.\n",
    "\n",
    "## Prerequisites\n",
    "To run this notebook, you need to install AML SDK and its widget extension in your environment by running the following commands in a terminal. Before running the commands, you need to activate your environment by executing `activate <your env>` or `source activate <your env>` in a Linux VM.   \n",
    "`pip3 install --upgrade azureml-sdk[notebooks,automl]`  \n",
    "`jupyter nbextension install --py --user azureml.train.widgets`  \n",
    "`jupyter nbextension enable --py --user azureml.train.widgets`  \n",
    "\n",
    "Besides, you need to create an Azure ML workspace and its configuration file (`config.json`) by following the [00.configuration.ipynb](https://github.com/Azure/MachineLearningNotebooks/blob/master/00.configuration.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  0.1.74\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "# Opt-in diagnostics for better experience of future releases\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace & Create an Azure ML Experiment\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` below creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /home/chenhui/TSPerf/retail_sales/OrangeJuice_Pt_3Weeks_Weekly/submissions/DilatedCNN/config.json\n",
      "Workspace name: chhws\n",
      "Azure region: southcentralus\n",
      "Subscription id: ff18d7a8-962a-406c-858f-49acd23d6c01\n",
      "Resource group: tsperf\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tune_dcnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Script Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Configure local, user managed environment\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "run_config_user_managed.environment.python.interpreter_path = '/usr/bin/python3.5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory='./', \n",
    "                      script='train_validate.py', \n",
    "                      arguments=['--data-folder', '/home/chenhui/TSPerf/retail_sales/OrangeJuice_Pt_3Weeks_Weekly/data/', '--dropout-rate', '0.3'],\n",
    "                      run_config=run_config_user_managed)\n",
    "run_local = exp.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Run.fail of Run(Experiment: tune_dcnn,\n",
       "Id: tune_dcnn_1543443482_13116394,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check job status\n",
    "run_local.fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAPE': 53.67131952139047}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "run_local.get_details()\n",
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script on BatchAI "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Batch AI cluster as compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target gpucluster.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your cluster\n",
    "cluster_name = \"gpucluster\"\n",
    "\n",
    "try:\n",
    "    # Look for the existing cluster by name\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('Found existing compute target {}.'.format(cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\", # GPU-based VM\n",
    "                                                                #vm_priority='lowpriority', # optional\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=0, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # Create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "    \n",
    "    # Can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpucluster BatchAI Succeeded\n"
     ]
    }
   ],
   "source": [
    "# If you have created the compute target, you should see one entry named 'gpucluster' of type BatchAI \n",
    "# in the workspace's compute_targets property.\n",
    "compute_targets = ws.compute_targets\n",
    "for name, ct in compute_targets.items():\n",
    "    print(name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'numpy', 'scipy', 'scikit-learn', 'tensorflow-gpu', 'keras', 'joblib'],\n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to default datastore\n",
    "\n",
    "Upload training and test sets of Orange Juice dataset to the workspace's default datastore, which will later be mounted on a Batch AI cluster for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureFile chhws9475974549 azureml-filestore-87c07697-2faa-418a-a879-bbaddc5c7cac\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_752662519aaf4f4894f19ee0e72cebcf"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_on_datastore = 'data'\n",
    "ds.upload(src_dir='../../data', target_path=path_on_datastore, overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_912122ef541340f2962f3b1f82e1cb3d\n"
     ]
    }
   ],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = ds.path(path_on_datastore)\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds_data.as_mount(),\n",
    "    '--dropout-rate': 0.3,\n",
    "    '--learning-rate': 0.01\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validate.py',\n",
    "                environment_definition=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to Batch AI cluster\n",
    "run_batchai = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fbe157e171a427fa7692fa0f4d1a0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "\n",
    "RunDetails(run_batchai).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'endTimeUtc': '2018-11-29T19:08:42.856806Z',\n",
       " 'logFiles': {'azureml-logs/55_batchai_execution.txt': 'https://chhws9475974549.blob.core.windows.net/azureml/ExperimentRun/tune_dcnn_1543516606666/azureml-logs/55_batchai_execution.txt?sv=2017-04-17&sr=b&sig=%2FHDbsKX1j3jPtIqbYv1WW%2Fsl8vA%2FSAYc4eU9cj4OEPw%3D&st=2018-11-29T19%3A01%3A09Z&se=2018-11-30T03%3A11%3A09Z&sp=r',\n",
       "  'azureml-logs/56_batchai_stderr.txt': 'https://chhws9475974549.blob.core.windows.net/azureml/ExperimentRun/tune_dcnn_1543516606666/azureml-logs/56_batchai_stderr.txt?sv=2017-04-17&sr=b&sig=2gJ0v%2Ffs7CXZH7rP7MyrJo8hd2JjS1N%2B5tqoCB3oqK0%3D&st=2018-11-29T19%3A01%3A09Z&se=2018-11-30T03%3A11%3A09Z&sp=r',\n",
       "  'azureml-logs/60_control_log.txt': 'https://chhws9475974549.blob.core.windows.net/azureml/ExperimentRun/tune_dcnn_1543516606666/azureml-logs/60_control_log.txt?sv=2017-04-17&sr=b&sig=gIT07ajS0f%2Furau5Wk8vh9tA%2FPL%2B9nMBw6EHyds8EB0%3D&st=2018-11-29T19%3A01%3A09Z&se=2018-11-30T03%3A11%3A09Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://chhws9475974549.blob.core.windows.net/azureml/ExperimentRun/tune_dcnn_1543516606666/azureml-logs/80_driver_log.txt?sv=2017-04-17&sr=b&sig=Np5TKX0%2Fj65bhgeWyI37KPJJEOXBsgfMZLpWa%2BQNXhM%3D&st=2018-11-29T19%3A01%3A09Z&se=2018-11-30T03%3A11%3A09Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://chhws9475974549.blob.core.windows.net/azureml/ExperimentRun/tune_dcnn_1543516606666/azureml-logs/azureml.log?sv=2017-04-17&sr=b&sig=Bg%2B7bQ6LXAT8uyGaQznCCuB3rD0GHsHFaey%2BVqeLeqU%3D&st=2018-11-29T19%3A01%3A09Z&se=2018-11-30T03%3A11%3A09Z&sp=r'},\n",
       " 'properties': {'ContentSnapshotId': '6a1267b8-9611-4ba9-9ce2-c8d46c150b61',\n",
       "  'azureml.runsource': 'experiment'},\n",
       " 'runDefinition': {'AmlCompute': {'ClusterMaxNodeCount': 1,\n",
       "   'Name': None,\n",
       "   'RetainCluster': False,\n",
       "   'VmPriority': None,\n",
       "   'VmSize': None},\n",
       "  'Arguments': ['--data-folder',\n",
       "   '$AZUREML_DATAREFERENCE_f463a2b0c5594532896997fa7b3ebe5e',\n",
       "   '--dropout-rate',\n",
       "   '0.3',\n",
       "   '--learning-rate',\n",
       "   '0.01'],\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'Communicator': 0,\n",
       "  'ContainerInstance': {'CpuCores': 1, 'MemoryGb': 4, 'Region': None},\n",
       "  'DataReferences': {'f463a2b0c5594532896997fa7b3ebe5e': {'DataStoreName': 'workspacefilestore',\n",
       "    'Mode': 'Mount',\n",
       "    'Overwrite': False,\n",
       "    'PathOnCompute': None,\n",
       "    'PathOnDataStore': 'data'}},\n",
       "  'Environment': {'Docker': {'Arguments': [],\n",
       "    'BaseImage': 'mcr.microsoft.com/azureml/base:0.1.4',\n",
       "    'BaseImageRegistry': {'Address': None, 'Password': None, 'Username': None},\n",
       "    'Enabled': True,\n",
       "    'GpuSupport': False,\n",
       "    'Preparation': None,\n",
       "    'SharedVolumes': True},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Python': {'CondaDependencies': {'channels': ['conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==0.1.74']},\n",
       "      'pandas',\n",
       "      'numpy',\n",
       "      'scipy',\n",
       "      'scikit-learn',\n",
       "      'tensorflow-gpu',\n",
       "      'keras',\n",
       "      'joblib'],\n",
       "     'name': 'project_environment'},\n",
       "    'CondaDependenciesFile': None,\n",
       "    'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False},\n",
       "   'Spark': {'Packages': [{'Artifact': 'mmlspark_2.11',\n",
       "      'Group': 'com.microsoft.ml.spark',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True,\n",
       "    'Repositories': ['https://mmlspark.azureedge.net/maven']}},\n",
       "  'ExposedPorts': None,\n",
       "  'Framework': 0,\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'JobName': None,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'NodeCount': 1,\n",
       "  'PrepareEnvironment': None,\n",
       "  'Script': 'train_validate.py',\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'Target': 'gpucluster',\n",
       "  'Tensorflow': {'ParameterServerCount': 1, 'WorkerCount': 1}},\n",
       " 'runId': 'tune_dcnn_1543516606666',\n",
       " 'startTimeUtc': '2018-11-29T19:06:39.912323Z',\n",
       " 'status': 'Completed',\n",
       " 'target': 'gpucluster'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAPE': 51.45909094199156}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "script_folder = './'\n",
    "script_params = {\n",
    "    '--data-folder': ds_data.as_mount()\n",
    "}\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validate.py',\n",
    "\n",
    "                environment_definition=env)\n",
    "ps = RandomParameterSampling({\n",
    "    '--seq-len': choice(6, 8, 10, 12, 14, 16, 18, 20),\n",
    "    '--batch-size': choice(16, 32, 64),\n",
    "    '--learning-rate': choice(0.01, 0.015, 0.02, 0.025),\n",
    "    '--epochs': choice(3,4,5,6,8)\n",
    "})\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='MAPE', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=20,\n",
    "                          max_concurrent_runs=4)\n",
    "htr = exp.submit(config=htc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9353c77ed44c979f992496713dd556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDrive(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(htr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tune_dcnn_1543519296309_0': {'MAPE': [52.406915348521984]},\n",
       " 'tune_dcnn_1543519296309_1': {'MAPE': [48.22620680559373]},\n",
       " 'tune_dcnn_1543519296309_10': {'MAPE': [45.50651538777104]},\n",
       " 'tune_dcnn_1543519296309_11': {'MAPE': [53.624342050763744]},\n",
       " 'tune_dcnn_1543519296309_12': {'MAPE': [50.111951512463456]},\n",
       " 'tune_dcnn_1543519296309_13': {'MAPE': [47.39905703800912]},\n",
       " 'tune_dcnn_1543519296309_14': {'MAPE': [45.82307980941858]},\n",
       " 'tune_dcnn_1543519296309_15': {'MAPE': [55.16572770960648]},\n",
       " 'tune_dcnn_1543519296309_16': {'MAPE': [52.154747659311084]},\n",
       " 'tune_dcnn_1543519296309_17': {'MAPE': [47.836595551418156]},\n",
       " 'tune_dcnn_1543519296309_18': {'MAPE': [47.548769835232136]},\n",
       " 'tune_dcnn_1543519296309_19': {'MAPE': [51.587706457682664]},\n",
       " 'tune_dcnn_1543519296309_2': {'MAPE': [47.51181064242932]},\n",
       " 'tune_dcnn_1543519296309_3': {'MAPE': [55.49454015575376]},\n",
       " 'tune_dcnn_1543519296309_4': {'MAPE': [49.35784863332553]},\n",
       " 'tune_dcnn_1543519296309_5': {'MAPE': [45.99110019145163]},\n",
       " 'tune_dcnn_1543519296309_6': {'MAPE': [44.66842268451283]},\n",
       " 'tune_dcnn_1543519296309_7': {'MAPE': [48.988083668244194]},\n",
       " 'tune_dcnn_1543519296309_8': {'MAPE': [51.72013804187461]},\n",
       " 'tune_dcnn_1543519296309_9': {'MAPE': [47.87281273315907]}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htr.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data-folder', '$AZUREML_DATAREFERENCE_b70efd6708e94a6d927566fa15263a0d', '--batch-size', '16', '--epochs', '8', '--learning-rate', '0.01', '--seq-len', '16']\n"
     ]
    }
   ],
   "source": [
    "best_run = htr.get_best_run_by_primary_metric()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "print(parameter_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
