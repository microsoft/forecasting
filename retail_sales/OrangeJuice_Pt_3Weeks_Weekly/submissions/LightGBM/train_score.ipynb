{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and score a boosted decision tree model using [LightGBM Python package](https://github.com/Microsoft/LightGBM) from Microsoft, which is a fast, distributed, high performance gradient boosting framework based on decision tree algorithms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import itertools\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append TSPerf path to sys.path\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "tsperf_dir = os.path.dirname(os.path.dirname(os.path.dirname(nb_dir)))\n",
    "if tsperf_dir not in sys.path:\n",
    "    sys.path.append(tsperf_dir)\n",
    "\n",
    "from common.metrics import MAPE\n",
    "import retail_sales.OrangeJuice_Pt_3Weeks_Weekly.common.benchmark_settings as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "DATA_DIR = '../../data'\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n",
    "TEST_DIR = os.path.join(DATA_DIR, 'test')\n",
    "\n",
    "# Parameters of GBM model\n",
    "params = {\n",
    "    'num_leaves': 60, #80,\n",
    "    'objective': 'regression',\n",
    "    'min_data_in_leaf': 200, #200,\n",
    "    'learning_rate': 0.02, #0.02,\n",
    "    'feature_fraction': 0.6, #0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    'metric': 'l2',\n",
    "    'num_threads': 16\n",
    "}\n",
    "params = {\n",
    "    'num_leaves': 50, #100, #80,\n",
    "    'objective': 'mape', ''#'regression',\n",
    "    'min_data_in_leaf': 200, #200,\n",
    "    'learning_rate': 0.002, #0.002, #0.02 #0.02,\n",
    "    'feature_fraction': 0.9, #0.6, #0.8,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 1,\n",
    "    #'metric': 'l2',\n",
    "    'num_threads': 16\n",
    "}\n",
    "MAX_ROUNDS = 100 #100 #4000 \n",
    "\n",
    "# Lags and categorical features\n",
    "lags = [2,3,4] #[2,3,4]\n",
    "lags_str = [str(x) for x in lags]\n",
    "#categ_fea = [''.join(res) for res in itertools.product(['deal_lag', 'feat_lag'], lags_str)]\n",
    "categ_fea = ['deal', 'feat']\n",
    "categ_fea = ['store', 'brand'] + categ_fea\n",
    "\n",
    "first_week_start = pd.to_datetime('1989-09-07 00:00:00') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def week_of_month(dt):\n",
    "    \"\"\" \n",
    "    Get the week of the month for the specified date.\n",
    "    \n",
    "    Args: \n",
    "        dt (Datetime): Input date\n",
    "        \n",
    "    Returns:\n",
    "        wom (Integer): Week of the month of the input date\n",
    "    \"\"\" \n",
    "    from math import ceil\n",
    "    first_day = dt.replace(day=1)\n",
    "    dom = dt.day\n",
    "    adjusted_dom = dom + first_day.weekday()\n",
    "    wom = int(ceil(adjusted_dom/7.0))\n",
    "    return wom\n",
    "\n",
    "def df_from_cartesian_product(dict_in):\n",
    "    \"\"\"Generate a Pandas dataframe from Cartesian product of lists.\n",
    "    \n",
    "    Args: \n",
    "        dict_in (Dictionary): Dictionary containing multiple lists\n",
    "        \n",
    "    Returns:\n",
    "        df (Dataframe): Dataframe corresponding to the Caresian product of the lists\n",
    "    \"\"\"\n",
    "    from collections import OrderedDict\n",
    "    from itertools import product\n",
    "    od = OrderedDict(sorted(dict_in.items()))\n",
    "    cart = list(product(*od.values()))\n",
    "    df = pd.DataFrame(cart, columns=od.keys())\n",
    "    return df\n",
    "\n",
    "def lagged_features(df, lags):\n",
    "    \"\"\"Create lagged features based on time series data.\n",
    "    \n",
    "    Args:\n",
    "        df (Dataframe): Input time series data sorted by time\n",
    "        lags (List): Lag lengths\n",
    "        \n",
    "    Returns:\n",
    "        fea (Dataframe): Lagged features \n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        df_shifted = df.shift(lag)\n",
    "        df_shifted.columns = [x + '_lag' + str(lag) for x in df_shifted.columns]\n",
    "        df_list.append(df_shifted)\n",
    "    fea = pd.concat(df_list, axis=1)\n",
    "    return fea\n",
    "\n",
    "def moving_averages(df, start_step, window_size=None):\n",
    "    \"\"\"\n",
    "    Compute averages of every feature over moving time windows.\n",
    "    \n",
    "    Args:\n",
    "        df (Dataframe): Input features as a dataframe\n",
    "    \n",
    "    Returns:\n",
    "        fea (Dataframe): Dataframe consisting of the moving averages\n",
    "    \"\"\"\n",
    "    if window_size == None: # Use a large window to compute average over all historical data\n",
    "        window_size = df.shape[0]\n",
    "    fea = df.shift(start_step).rolling(min_periods=1, center=False, window=window_size).mean()\n",
    "    fea.columns = fea.columns + '_mean'\n",
    "    return fea\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Create features used for model training.\n",
    "    \n",
    "    Args:\n",
    "        df (Dataframe): Time series data of a certain store and brand\n",
    "    \n",
    "    Returns:\n",
    "        fea_all (Dataframe): All features for the specific store and brand\n",
    "    \"\"\"\n",
    "    lagged_fea = lagged_features(df[['move']], lags)\n",
    "    moving_avg = moving_averages(df[['move']], 2, 10)\n",
    "    fea_columns = ['brand' , 'store', 'week', 'week_of_month', 'day', 'profit', 'deal' , 'feat', 'move']\n",
    "    #fea_columns = fea_columns + ['price1', 'price2', 'price3', 'price4', 'price5', 'price6', 'price7', 'price8', 'price9', 'price10', 'price11']\n",
    "    fea_all = pd.concat([df[fea_columns], lagged_fea, moving_avg], axis=1)\n",
    "    return fea_all\n",
    "\n",
    "def make_predictions(df, model):\n",
    "    \"\"\"\n",
    "    Predict sales with the trained GBM model.\n",
    "    \n",
    "    Args: \n",
    "        df (Dataframe): Dataframe including all needed features\n",
    "        model (Model): Trained GBM model\n",
    "        \n",
    "    Returns:\n",
    "        Dataframe including the predicted sales of a certain store and brand\n",
    "    \"\"\"\n",
    "    predictions = pd.DataFrame({'move': model.predict(df.drop('move', axis=1))})\n",
    "    predictions['move'] = predictions['move'].apply(lambda x: round(x))\n",
    "    return pd.concat([df[['brand', 'store', 'week']].reset_index(drop=True), predictions], axis=1)\n",
    "\n",
    "def evaluate(pred, actual):\n",
    "    \"\"\"\n",
    "    Compute MAPE value of the forecast.\n",
    "    \n",
    "    Args:\n",
    "        pred (Dataframe): Predicted sales\n",
    "        actual (Dataframe): Actual sales\n",
    "    \n",
    "    Returns:\n",
    "        MAPE value of the forecast\n",
    "    \"\"\"\n",
    "    return MAPE(pred['move'], actual['move'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Round 1 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6204\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenhui/.local/lib/python3.5/site-packages/lightgbm/basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['brand', 'deal', 'feat', 'store']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's mape: 0.761025\n",
      "[40]\ttraining's mape: 0.742859\n",
      "[60]\ttraining's mape: 0.725362\n",
      "[80]\ttraining's mape: 0.70905\n",
      "[100]\ttraining's mape: 0.693508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.693508\n",
      "      brand  store  week  move\n",
      "0         1      2   137  2161\n",
      "1         1      2   138  2161\n",
      "2         2      2   137  2193\n",
      "3         2      2   138  2282\n",
      "4         3      2   137  1359\n",
      "5         3      2   138  1362\n",
      "6         4      2   137  1646\n",
      "7         4      2   138  1582\n",
      "8         5      2   137  1994\n",
      "9         5      2   138  2055\n",
      "10        6      2   137  1289\n",
      "11        6      2   138  1242\n",
      "12        7      2   137  1385\n",
      "13        7      2   138  1375\n",
      "14        8      2   137  1190\n",
      "15        8      2   138  1201\n",
      "16        9      2   137  1330\n",
      "17        9      2   138  1325\n",
      "18       10      2   137  2044\n",
      "19       10      2   138  2025\n",
      "20       11      2   137  1985\n",
      "21       11      2   138  2083\n",
      "22        1      5   137  2153\n",
      "23        1      5   138  2153\n",
      "24        2      5   137  2300\n",
      "25        2      5   138  2300\n",
      "26        3      5   137  1434\n",
      "27        3      5   138  1463\n",
      "28        4      5   137  1564\n",
      "29        4      5   138  1547\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   137  1097\n",
      "1797      8    134   138  1102\n",
      "1798      9    134   137  1232\n",
      "1799      9    134   138  1273\n",
      "1800     10    134   137  1974\n",
      "1801     10    134   138  2024\n",
      "1802     11    134   137  2342\n",
      "1803     11    134   138  2342\n",
      "1804      1    137   137  2160\n",
      "1805      1    137   138  2160\n",
      "1806      2    137   137  2304\n",
      "1807      2    137   138  2304\n",
      "1808      3    137   137  1516\n",
      "1809      3    137   138  1519\n",
      "1810      4    137   137  1661\n",
      "1811      4    137   138  1600\n",
      "1812      5    137   137  2063\n",
      "1813      5    137   138  2063\n",
      "1814      6    137   137  1507\n",
      "1815      6    137   138  1503\n",
      "1816      7    137   137  1555\n",
      "1817      7    137   138  1645\n",
      "1818      8    137   137  1192\n",
      "1819      8    137   138  1202\n",
      "1820      9    137   137  1320\n",
      "1821      9    137   138  1335\n",
      "1822     10    137   137  2110\n",
      "1823     10    137   138  2110\n",
      "1824     11    137   137  2342\n",
      "1825     11    137   138  2342\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 62.86460774822484\n",
      "\n",
      "---- Round 2 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6215\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenhui/.local/lib/python3.5/site-packages/lightgbm/basic.py:1042: UserWarning: categorical_feature in Dataset is overridden. New categorical_feature is ['brand', 'deal', 'feat', 'store']\n",
      "  warnings.warn('categorical_feature in Dataset is overridden. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n",
      "/home/chenhui/.local/lib/python3.5/site-packages/lightgbm/basic.py:685: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\ttraining's mape: 0.759219\n",
      "[40]\ttraining's mape: 0.741191\n",
      "[60]\ttraining's mape: 0.723989\n",
      "[80]\ttraining's mape: 0.70795\n",
      "[100]\ttraining's mape: 0.692696\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.692696\n",
      "      brand  store  week  move\n",
      "0         1      2   139  2051\n",
      "1         1      2   140  2053\n",
      "2         2      2   139  2038\n",
      "3         2      2   140  2023\n",
      "4         3      2   139  1437\n",
      "5         3      2   140  1437\n",
      "6         4      2   139  1804\n",
      "7         4      2   140  1819\n",
      "8         5      2   139  2428\n",
      "9         5      2   140  2457\n",
      "10        6      2   139  1491\n",
      "11        6      2   140  1806\n",
      "12        7      2   139  1516\n",
      "13        7      2   140  1478\n",
      "14        8      2   139  1237\n",
      "15        8      2   140  1236\n",
      "16        9      2   139  1138\n",
      "17        9      2   140  1135\n",
      "18       10      2   139  2051\n",
      "19       10      2   140  2051\n",
      "20       11      2   139  1504\n",
      "21       11      2   140  1493\n",
      "22        1      5   139  1894\n",
      "23        1      5   140  1894\n",
      "24        2      5   139  2015\n",
      "25        2      5   140  2010\n",
      "26        3      5   139  1516\n",
      "27        3      5   140  1494\n",
      "28        4      5   139  1519\n",
      "29        4      5   140  1501\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   139  1138\n",
      "1797      8    134   140  1133\n",
      "1798      9    134   139  1252\n",
      "1799      9    134   140  1237\n",
      "1800     10    134   139  2021\n",
      "1801     10    134   140  2021\n",
      "1802     11    134   139  2024\n",
      "1803     11    134   140  2024\n",
      "1804      1    137   139  1958\n",
      "1805      1    137   140  1958\n",
      "1806      2    137   139  2061\n",
      "1807      2    137   140  2061\n",
      "1808      3    137   139  1585\n",
      "1809      3    137   140  1548\n",
      "1810      4    137   139  1671\n",
      "1811      4    137   140  1674\n",
      "1812      5    137   139  2466\n",
      "1813      5    137   140  2466\n",
      "1814      6    137   139  1868\n",
      "1815      6    137   140  1909\n",
      "1816      7    137   139  1776\n",
      "1817      7    137   140  1808\n",
      "1818      8    137   139  1255\n",
      "1819      8    137   140  1264\n",
      "1820      9    137   139  1139\n",
      "1821      9    137   140  1134\n",
      "1822     10    137   139  2053\n",
      "1823     10    137   140  2053\n",
      "1824     11    137   139  2061\n",
      "1825     11    137   140  2035\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 62.85048399669263\n",
      "\n",
      "---- Round 3 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6237\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.757498\n",
      "[40]\ttraining's mape: 0.739667\n",
      "[60]\ttraining's mape: 0.722431\n",
      "[80]\ttraining's mape: 0.70659\n",
      "[100]\ttraining's mape: 0.691581\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.691581\n",
      "      brand  store  week  move\n",
      "0         1      2   141  1969\n",
      "1         1      2   142  1969\n",
      "2         2      2   141  2019\n",
      "3         2      2   142  2056\n",
      "4         3      2   141  1893\n",
      "5         3      2   142  1793\n",
      "6         4      2   141  1644\n",
      "7         4      2   142  1640\n",
      "8         5      2   141  1765\n",
      "9         5      2   142  1747\n",
      "10        6      2   141  1447\n",
      "11        6      2   142  1432\n",
      "12        7      2   141  1811\n",
      "13        7      2   142  1890\n",
      "14        8      2   141  1246\n",
      "15        8      2   142  1252\n",
      "16        9      2   141  1140\n",
      "17        9      2   142  1149\n",
      "18       10      2   141  1946\n",
      "19       10      2   142  1946\n",
      "20       11      2   141  1497\n",
      "21       11      2   142  1497\n",
      "22        1      5   141  1984\n",
      "23        1      5   142  1984\n",
      "24        2      5   141  2054\n",
      "25        2      5   142  2076\n",
      "26        3      5   141  1974\n",
      "27        3      5   142  2054\n",
      "28        4      5   141  1577\n",
      "29        4      5   142  1524\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   141  1150\n",
      "1797      8    134   142  1152\n",
      "1798      9    134   141  1294\n",
      "1799      9    134   142  1322\n",
      "1800     10    134   141  1859\n",
      "1801     10    134   142  1837\n",
      "1802     11    134   141  2082\n",
      "1803     11    134   142  2082\n",
      "1804      1    137   141  1978\n",
      "1805      1    137   142  1978\n",
      "1806      2    137   141  2081\n",
      "1807      2    137   142  2081\n",
      "1808      3    137   141  1986\n",
      "1809      3    137   142  2367\n",
      "1810      4    137   141  1656\n",
      "1811      4    137   142  1628\n",
      "1812      5    137   141  1824\n",
      "1813      5    137   142  1824\n",
      "1814      6    137   141  1622\n",
      "1815      6    137   142  1668\n",
      "1816      7    137   141  2206\n",
      "1817      7    137   142  2288\n",
      "1818      8    137   141  1286\n",
      "1819      8    137   142  1321\n",
      "1820      9    137   141  1129\n",
      "1821      9    137   142  1122\n",
      "1822     10    137   141  1954\n",
      "1823     10    137   142  1954\n",
      "1824     11    137   141  2081\n",
      "1825     11    137   142  2045\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 65.5248704391305\n",
      "\n",
      "---- Round 4 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6248\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.755884\n",
      "[40]\ttraining's mape: 0.738096\n",
      "[60]\ttraining's mape: 0.721154\n",
      "[80]\ttraining's mape: 0.705471\n",
      "[100]\ttraining's mape: 0.690548\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.690548\n",
      "      brand  store  week  move\n",
      "0         1      2   143  1978\n",
      "1         1      2   144  1973\n",
      "2         2      2   143  2053\n",
      "3         2      2   144  2053\n",
      "4         3      2   143  1527\n",
      "5         3      2   144  1497\n",
      "6         4      2   143  1624\n",
      "7         4      2   144  1607\n",
      "8         5      2   143  2405\n",
      "9         5      2   144  2454\n",
      "10        6      2   143  1820\n",
      "11        6      2   144  1826\n",
      "12        7      2   143  1641\n",
      "13        7      2   144  1427\n",
      "14        8      2   143  1292\n",
      "15        8      2   144  1390\n",
      "16        9      2   143  1151\n",
      "17        9      2   144  1153\n",
      "18       10      2   143  1947\n",
      "19       10      2   144  1928\n",
      "20       11      2   143  1999\n",
      "21       11      2   144  2010\n",
      "22        1      5   143  1998\n",
      "23        1      5   144  1998\n",
      "24        2      5   143  2060\n",
      "25        2      5   144  2060\n",
      "26        3      5   143  1548\n",
      "27        3      5   144  1499\n",
      "28        4      5   143  1458\n",
      "29        4      5   144  1413\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   143  1131\n",
      "1797      8    134   144  1126\n",
      "1798      9    134   143  1309\n",
      "1799      9    134   144  1308\n",
      "1800     10    134   143  1892\n",
      "1801     10    134   144  1926\n",
      "1802     11    134   143  2384\n",
      "1803     11    134   144  2384\n",
      "1804      1    137   143  1985\n",
      "1805      1    137   144  1985\n",
      "1806      2    137   143  2053\n",
      "1807      2    137   144  2053\n",
      "1808      3    137   143  1862\n",
      "1809      3    137   144  1826\n",
      "1810      4    137   143  1583\n",
      "1811      4    137   144  1577\n",
      "1812      5    137   143  2454\n",
      "1813      5    137   144  2454\n",
      "1814      6    137   143  1833\n",
      "1815      6    137   144  1915\n",
      "1816      7    137   143  1690\n",
      "1817      7    137   144  1565\n",
      "1818      8    137   143  1212\n",
      "1819      8    137   144  1205\n",
      "1820      9    137   143  1114\n",
      "1821      9    137   144  1117\n",
      "1822     10    137   143  1987\n",
      "1823     10    137   144  1944\n",
      "1824     11    137   143  2384\n",
      "1825     11    137   144  2384\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 59.79490622931149\n",
      "\n",
      "---- Round 5 ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6358\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.753935\n",
      "[40]\ttraining's mape: 0.736279\n",
      "[60]\ttraining's mape: 0.719308\n",
      "[80]\ttraining's mape: 0.703736\n",
      "[100]\ttraining's mape: 0.688979\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.688979\n",
      "      brand  store  week  move\n",
      "0         1      2   145  2477\n",
      "1         1      2   146  2477\n",
      "2         2      2   145  1988\n",
      "3         2      2   146  1974\n",
      "4         3      2   145  1552\n",
      "5         3      2   146  1486\n",
      "6         4      2   145  2401\n",
      "7         4      2   146  2420\n",
      "8         5      2   145  1666\n",
      "9         5      2   146  1644\n",
      "10        6      2   145  1480\n",
      "11        6      2   146  1469\n",
      "12        7      2   145  1347\n",
      "13        7      2   146  1308\n",
      "14        8      2   145  1278\n",
      "15        8      2   146  1246\n",
      "16        9      2   145  1267\n",
      "17        9      2   146  1265\n",
      "18       10      2   145  1980\n",
      "19       10      2   146  1980\n",
      "20       11      2   145  1604\n",
      "21       11      2   146  1517\n",
      "22        1      5   145  2477\n",
      "23        1      5   146  2477\n",
      "24        2      5   145  2025\n",
      "25        2      5   146  2007\n",
      "26        3      5   145  1531\n",
      "27        3      5   146  1489\n",
      "28        4      5   145  1589\n",
      "29        4      5   146  1980\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   145  1123\n",
      "1797      8    134   146  1124\n",
      "1798      9    134   145  1313\n",
      "1799      9    134   146  1302\n",
      "1800     10    134   145  1973\n",
      "1801     10    134   146  1973\n",
      "1802     11    134   145  2050\n",
      "1803     11    134   146  2050\n",
      "1804      1    137   145  2477\n",
      "1805      1    137   146  2477\n",
      "1806      2    137   145  2058\n",
      "1807      2    137   146  2058\n",
      "1808      3    137   145  1845\n",
      "1809      3    137   146  1849\n",
      "1810      4    137   145  2415\n",
      "1811      4    137   146  2423\n",
      "1812      5    137   145  1769\n",
      "1813      5    137   146  1767\n",
      "1814      6    137   145  1747\n",
      "1815      6    137   146  1734\n",
      "1816      7    137   145  1585\n",
      "1817      7    137   146  1562\n",
      "1818      8    137   145  1186\n",
      "1819      8    137   146  1184\n",
      "1820      9    137   145  1259\n",
      "1821      9    137   146  1260\n",
      "1822     10    137   145  1983\n",
      "1823     10    137   146  1983\n",
      "1824     11    137   145  2058\n",
      "1825     11    137   146  2058\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 67.43158514409438\n",
      "\n",
      "---- Round 6 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6446\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.751776\n",
      "[40]\ttraining's mape: 0.734206\n",
      "[60]\ttraining's mape: 0.717386\n",
      "[80]\ttraining's mape: 0.701911\n",
      "[100]\ttraining's mape: 0.687094\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.687094\n",
      "      brand  store  week  move\n",
      "0         1      2   147  2526\n",
      "1         1      2   148  2526\n",
      "2         2      2   147  2006\n",
      "3         2      2   148  2035\n",
      "4         3      2   147  1449\n",
      "5         3      2   148  1448\n",
      "6         4      2   147  1928\n",
      "7         4      2   148  1920\n",
      "8         5      2   147  1651\n",
      "9         5      2   148  1651\n",
      "10        6      2   147  1798\n",
      "11        6      2   148  1822\n",
      "12        7      2   147  1305\n",
      "13        7      2   148  1328\n",
      "14        8      2   147  1272\n",
      "15        8      2   148  1274\n",
      "16        9      2   147  1274\n",
      "17        9      2   148  1273\n",
      "18       10      2   147  1886\n",
      "19       10      2   148  1882\n",
      "20       11      2   147  1609\n",
      "21       11      2   148  1560\n",
      "22        1      5   147  2096\n",
      "23        1      5   148  2096\n",
      "24        2      5   147  2039\n",
      "25        2      5   148  2079\n",
      "26        3      5   147  1480\n",
      "27        3      5   148  1480\n",
      "28        4      5   147  1216\n",
      "29        4      5   148  1208\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   147  1146\n",
      "1797      8    134   148  1142\n",
      "1798      9    134   147  1304\n",
      "1799      9    134   148  1319\n",
      "1800     10    134   147  1886\n",
      "1801     10    134   148  1880\n",
      "1802     11    134   147  2059\n",
      "1803     11    134   148  2059\n",
      "1804      1    137   147  2526\n",
      "1805      1    137   148  2526\n",
      "1806      2    137   147  2063\n",
      "1807      2    137   148  2063\n",
      "1808      3    137   147  1823\n",
      "1809      3    137   148  1825\n",
      "1810      4    137   147  2398\n",
      "1811      4    137   148  2384\n",
      "1812      5    137   147  1738\n",
      "1813      5    137   148  1762\n",
      "1814      6    137   147  1843\n",
      "1815      6    137   148  1835\n",
      "1816      7    137   147  1586\n",
      "1817      7    137   148  1586\n",
      "1818      8    137   147  1272\n",
      "1819      8    137   148  1292\n",
      "1820      9    137   147  1275\n",
      "1821      9    137   148  1274\n",
      "1822     10    137   147  1990\n",
      "1823     10    137   148  1990\n",
      "1824     11    137   147  2063\n",
      "1825     11    137   148  2063\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 69.19679171303854\n",
      "\n",
      "---- Round 7 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6501\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.750002\n",
      "[40]\ttraining's mape: 0.732586\n",
      "[60]\ttraining's mape: 0.715789\n",
      "[80]\ttraining's mape: 0.700213\n",
      "[100]\ttraining's mape: 0.685408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.685408\n",
      "      brand  store  week  move\n",
      "0         1      2   149  2029\n",
      "1         1      2   150  1999\n",
      "2         2      2   149  2051\n",
      "3         2      2   150  2046\n",
      "4         3      2   149  1467\n",
      "5         3      2   150  1469\n",
      "6         4      2   149  2504\n",
      "7         4      2   150  2504\n",
      "8         5      2   149  2464\n",
      "9         5      2   150  2487\n",
      "10        6      2   149  1462\n",
      "11        6      2   150  1434\n",
      "12        7      2   149  1265\n",
      "13        7      2   150  1255\n",
      "14        8      2   149  1194\n",
      "15        8      2   150  1192\n",
      "16        9      2   149  1141\n",
      "17        9      2   150  1140\n",
      "18       10      2   149  1970\n",
      "19       10      2   150  2020\n",
      "20       11      2   149  1680\n",
      "21       11      2   150  1677\n",
      "22        1      5   149  2046\n",
      "23        1      5   150  2046\n",
      "24        2      5   149  2063\n",
      "25        2      5   150  2064\n",
      "26        3      5   149  1471\n",
      "27        3      5   150  1509\n",
      "28        4      5   149  1566\n",
      "29        4      5   150  2464\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   149  1134\n",
      "1797      8    134   150  1137\n",
      "1798      9    134   149  1272\n",
      "1799      9    134   150  1275\n",
      "1800     10    134   149  1893\n",
      "1801     10    134   150  1897\n",
      "1802     11    134   149  2057\n",
      "1803     11    134   150  2057\n",
      "1804      1    137   149  2049\n",
      "1805      1    137   150  2049\n",
      "1806      2    137   149  2066\n",
      "1807      2    137   150  2066\n",
      "1808      3    137   149  1935\n",
      "1809      3    137   150  1983\n",
      "1810      4    137   149  2504\n",
      "1811      4    137   150  2504\n",
      "1812      5    137   149  2504\n",
      "1813      5    137   150  2504\n",
      "1814      6    137   149  1604\n",
      "1815      6    137   150  1551\n",
      "1816      7    137   149  1576\n",
      "1817      7    137   150  1576\n",
      "1818      8    137   149  1223\n",
      "1819      8    137   150  1224\n",
      "1820      9    137   149  1141\n",
      "1821      9    137   150  1135\n",
      "1822     10    137   149  2010\n",
      "1823     10    137   150  2010\n",
      "1824     11    137   149  2057\n",
      "1825     11    137   150  2057\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 62.680936867199456\n",
      "\n",
      "---- Round 8 ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6578\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.748\n",
      "[40]\ttraining's mape: 0.730561\n",
      "[60]\ttraining's mape: 0.713938\n",
      "[80]\ttraining's mape: 0.698582\n",
      "[100]\ttraining's mape: 0.683853\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.683853\n",
      "      brand  store  week  move\n",
      "0         1      2   151  1996\n",
      "1         1      2   152  1971\n",
      "2         2      2   151  2052\n",
      "3         2      2   152  2034\n",
      "4         3      2   151  1482\n",
      "5         3      2   152  1496\n",
      "6         4      2   151  1604\n",
      "7         4      2   152  1582\n",
      "8         5      2   151  1645\n",
      "9         5      2   152  1655\n",
      "10        6      2   151  1795\n",
      "11        6      2   152  1778\n",
      "12        7      2   151  1286\n",
      "13        7      2   152  1305\n",
      "14        8      2   151  1240\n",
      "15        8      2   152  1241\n",
      "16        9      2   151  1256\n",
      "17        9      2   152  1265\n",
      "18       10      2   151  2009\n",
      "19       10      2   152  2009\n",
      "20       11      2   151  1538\n",
      "21       11      2   152  1496\n",
      "22        1      5   151  2007\n",
      "23        1      5   152  1993\n",
      "24        2      5   151  2076\n",
      "25        2      5   152  2076\n",
      "26        3      5   151  1489\n",
      "27        3      5   152  1483\n",
      "28        4      5   151  1635\n",
      "29        4      5   152  1609\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   151  1129\n",
      "1797      8    134   152  1128\n",
      "1798      9    134   151  1309\n",
      "1799      9    134   152  1306\n",
      "1800     10    134   151  1975\n",
      "1801     10    134   152  2000\n",
      "1802     11    134   151  2076\n",
      "1803     11    134   152  2076\n",
      "1804      1    137   151  2011\n",
      "1805      1    137   152  2011\n",
      "1806      2    137   151  2076\n",
      "1807      2    137   152  2076\n",
      "1808      3    137   151  1981\n",
      "1809      3    137   152  1977\n",
      "1810      4    137   151  1643\n",
      "1811      4    137   152  1624\n",
      "1812      5    137   151  1768\n",
      "1813      5    137   152  1768\n",
      "1814      6    137   151  1833\n",
      "1815      6    137   152  1850\n",
      "1816      7    137   151  1524\n",
      "1817      7    137   152  1649\n",
      "1818      8    137   151  1228\n",
      "1819      8    137   152  1219\n",
      "1820      9    137   151  1226\n",
      "1821      9    137   152  1227\n",
      "1822     10    137   151  2012\n",
      "1823     10    137   152  2017\n",
      "1824     11    137   151  2062\n",
      "1825     11    137   152  2041\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 57.861271942114314\n",
      "\n",
      "---- Round 9 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6655\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.745335\n",
      "[40]\ttraining's mape: 0.728133\n",
      "[60]\ttraining's mape: 0.711585\n",
      "[80]\ttraining's mape: 0.696347\n",
      "[100]\ttraining's mape: 0.681728\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.681728\n",
      "      brand  store  week  move\n",
      "0         1      2   153  1911\n",
      "1         1      2   154  1902\n",
      "2         2      2   153  2063\n",
      "3         2      2   154  2057\n",
      "4         3      2   153  1537\n",
      "5         3      2   154  1486\n",
      "6         4      2   153  1503\n",
      "7         4      2   154  1389\n",
      "8         5      2   153  1642\n",
      "9         5      2   154  1642\n",
      "10        6      2   153  1440\n",
      "11        6      2   154  1437\n",
      "12        7      2   153  1331\n",
      "13        7      2   154  1328\n",
      "14        8      2   153  1229\n",
      "15        8      2   154  1221\n",
      "16        9      2   153  1239\n",
      "17        9      2   154  1238\n",
      "18       10      2   153  2450\n",
      "19       10      2   154  2450\n",
      "20       11      2   153  1609\n",
      "21       11      2   154  1636\n",
      "22        1      5   153  2011\n",
      "23        1      5   154  1983\n",
      "24        2      5   153  2069\n",
      "25        2      5   154  2069\n",
      "26        3      5   153  1475\n",
      "27        3      5   154  1475\n",
      "28        4      5   153  1486\n",
      "29        4      5   154  1328\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   153  1130\n",
      "1797      8    134   154  1139\n",
      "1798      9    134   153  1293\n",
      "1799      9    134   154  1292\n",
      "1800     10    134   153  2431\n",
      "1801     10    134   154  2454\n",
      "1802     11    134   153  2057\n",
      "1803     11    134   154  2047\n",
      "1804      1    137   153  2031\n",
      "1805      1    137   154  2031\n",
      "1806      2    137   153  2077\n",
      "1807      2    137   154  2077\n",
      "1808      3    137   153  1957\n",
      "1809      3    137   154  1723\n",
      "1810      4    137   153  1606\n",
      "1811      4    137   154  1612\n",
      "1812      5    137   153  1761\n",
      "1813      5    137   154  1761\n",
      "1814      6    137   153  1529\n",
      "1815      6    137   154  1555\n",
      "1816      7    137   153  1478\n",
      "1817      7    137   154  1472\n",
      "1818      8    137   153  1238\n",
      "1819      8    137   154  1239\n",
      "1820      9    137   153  1225\n",
      "1821      9    137   154  1222\n",
      "1822     10    137   153  2454\n",
      "1823     10    137   154  2454\n",
      "1824     11    137   153  1919\n",
      "1825     11    137   154  1898\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 74.21557572784995\n",
      "\n",
      "---- Round 10 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6765\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.74419\n",
      "[40]\ttraining's mape: 0.727157\n",
      "[60]\ttraining's mape: 0.710871\n",
      "[80]\ttraining's mape: 0.695597\n",
      "[100]\ttraining's mape: 0.681217\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.681217\n",
      "      brand  store  week  move\n",
      "0         1      2   155  1902\n",
      "1         1      2   156  1891\n",
      "2         2      2   155  1999\n",
      "3         2      2   156  2014\n",
      "4         3      2   155  1541\n",
      "5         3      2   156  1496\n",
      "6         4      2   155  1642\n",
      "7         4      2   156  1629\n",
      "8         5      2   155  2324\n",
      "9         5      2   156  2370\n",
      "10        6      2   155  1340\n",
      "11        6      2   156  1342\n",
      "12        7      2   155  1339\n",
      "13        7      2   156  1330\n",
      "14        8      2   155  1247\n",
      "15        8      2   156  1256\n",
      "16        9      2   155  1112\n",
      "17        9      2   156  1115\n",
      "18       10      2   155  1870\n",
      "19       10      2   156  1856\n",
      "20       11      2   155  1570\n",
      "21       11      2   156  1508\n",
      "22        1      5   155  2014\n",
      "23        1      5   156  2018\n",
      "24        2      5   155  2045\n",
      "25        2      5   156  2045\n",
      "26        3      5   155  1400\n",
      "27        3      5   156  1383\n",
      "28        4      5   155  1638\n",
      "29        4      5   156  1622\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   155  1137\n",
      "1797      8    134   156  1134\n",
      "1798      9    134   155  1348\n",
      "1799      9    134   156  1346\n",
      "1800     10    134   155  1870\n",
      "1801     10    134   156  1680\n",
      "1802     11    134   155  2015\n",
      "1803     11    134   156  2041\n",
      "1804      1    137   155  2010\n",
      "1805      1    137   156  2010\n",
      "1806      2    137   155  2047\n",
      "1807      2    137   156  2047\n",
      "1808      3    137   155  1673\n",
      "1809      3    137   156  1666\n",
      "1810      4    137   155  1725\n",
      "1811      4    137   156  1759\n",
      "1812      5    137   155  2370\n",
      "1813      5    137   156  2370\n",
      "1814      6    137   155  1655\n",
      "1815      6    137   156  1700\n",
      "1816      7    137   155  1556\n",
      "1817      7    137   156  1478\n",
      "1818      8    137   155  1214\n",
      "1819      8    137   156  1210\n",
      "1820      9    137   155  1102\n",
      "1821      9    137   156  1101\n",
      "1822     10    137   155  1896\n",
      "1823     10    137   156  1870\n",
      "1824     11    137   155  1884\n",
      "1825     11    137   156  1800\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 77.13471677686479\n",
      "\n",
      "---- Round 11 ----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6875\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.744444\n",
      "[40]\ttraining's mape: 0.727326\n",
      "[60]\ttraining's mape: 0.710913\n",
      "[80]\ttraining's mape: 0.695875\n",
      "[100]\ttraining's mape: 0.681829\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.681829\n",
      "      brand  store  week  move\n",
      "0         1      2   157  1955\n",
      "1         1      2   158  1982\n",
      "2         2      2   157  1967\n",
      "3         2      2   158  1985\n",
      "4         3      2   157  1779\n",
      "5         3      2   158  1701\n",
      "6         4      2   157  2334\n",
      "7         4      2   158  2343\n",
      "8         5      2   157  1883\n",
      "9         5      2   158  1883\n",
      "10        6      2   157  1444\n",
      "11        6      2   158  1447\n",
      "12        7      2   157  1268\n",
      "13        7      2   158  1264\n",
      "14        8      2   157  1271\n",
      "15        8      2   158  1269\n",
      "16        9      2   157  1103\n",
      "17        9      2   158  1102\n",
      "18       10      2   157  2023\n",
      "19       10      2   158  2050\n",
      "20       11      2   157  1503\n",
      "21       11      2   158  1503\n",
      "22        1      5   157  1989\n",
      "23        1      5   158  1989\n",
      "24        2      5   157  2062\n",
      "25        2      5   158  2062\n",
      "26        3      5   157  1842\n",
      "27        3      5   158  1868\n",
      "28        4      5   157  2348\n",
      "29        4      5   158  2358\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   157  1143\n",
      "1797      8    134   158  1134\n",
      "1798      9    134   157  1227\n",
      "1799      9    134   158  1225\n",
      "1800     10    134   157  2023\n",
      "1801     10    134   158  2050\n",
      "1802     11    134   157  1987\n",
      "1803     11    134   158  2006\n",
      "1804      1    137   157  1982\n",
      "1805      1    137   158  1982\n",
      "1806      2    137   157  2052\n",
      "1807      2    137   158  2052\n",
      "1808      3    137   157  2267\n",
      "1809      3    137   158  2294\n",
      "1810      4    137   157  2343\n",
      "1811      4    137   158  2343\n",
      "1812      5    137   157  1883\n",
      "1813      5    137   158  1883\n",
      "1814      6    137   157  1588\n",
      "1815      6    137   158  1588\n",
      "1816      7    137   157  1467\n",
      "1817      7    137   158  1467\n",
      "1818      8    137   157  1256\n",
      "1819      8    137   158  1260\n",
      "1820      9    137   157  1128\n",
      "1821      9    137   158  1128\n",
      "1822     10    137   157  2023\n",
      "1823     10    137   158  2050\n",
      "1824     11    137   157  1786\n",
      "1825     11    137   158  1786\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 65.99813472630287\n",
      "\n",
      "---- Round 12 ----\n",
      "   store  brand  week  constant    price1    price2    price3    price4  \\\n",
      "0      2      1    40         1  0.060469  0.060497  0.042031  0.029531   \n",
      "1      2      1    46         1  0.060469  0.060312  0.045156  0.046719   \n",
      "2      2      1    47         1  0.060469  0.060312  0.045156  0.046719   \n",
      "\n",
      "     price5    price6    price7    price8    price9   price10   price11  deal  \\\n",
      "0  0.049531  0.053021  0.038906  0.041406  0.028906  0.024844  0.038984     1   \n",
      "1  0.049531  0.047813  0.045781  0.027969  0.042969  0.042031  0.038984     0   \n",
      "2  0.037344  0.053021  0.045781  0.041406  0.048125  0.032656  0.038984     0   \n",
      "\n",
      "   feat     profit  move  \n",
      "0   0.0  37.992326  8256  \n",
      "1   0.0  30.126667  6144  \n",
      "2   0.0  30.000000  3840  \n",
      "\n",
      "Number of missing rows is 6985\n",
      "\n",
      "   brand  store  week  week_of_month  day     profit  deal  feat    move  \\\n",
      "4      1      2    44              2    5  37.992326   1.0   0.0  8256.0   \n",
      "\n",
      "   move_lag2  move_lag3  move_lag4  move_mean  \n",
      "4     8256.0     8256.0     8256.0     8256.0  \n",
      "\n",
      "Training and predicting models...\n",
      "Training until validation scores don't improve for 125 rounds.\n",
      "[20]\ttraining's mape: 0.743597\n",
      "[40]\ttraining's mape: 0.726709\n",
      "[60]\ttraining's mape: 0.710364\n",
      "[80]\ttraining's mape: 0.695655\n",
      "[100]\ttraining's mape: 0.681434\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's mape: 0.681434\n",
      "      brand  store  week  move\n",
      "0         1      2   159  1980\n",
      "1         1      2   160  1980\n",
      "2         2      2   159  1743\n",
      "3         2      2   160  1743\n",
      "4         3      2   159  1469\n",
      "5         3      2   160  1461\n",
      "6         4      2   159  1655\n",
      "7         4      2   160  1632\n",
      "8         5      2   159  2381\n",
      "9         5      2   160  2381\n",
      "10        6      2   159  1429\n",
      "11        6      2   160  1424\n",
      "12        7      2   159  1289\n",
      "13        7      2   160  1298\n",
      "14        8      2   159  1288\n",
      "15        8      2   160  1290\n",
      "16        9      2   159  1097\n",
      "17        9      2   160  1099\n",
      "18       10      2   159  1803\n",
      "19       10      2   160  1806\n",
      "20       11      2   159  1676\n",
      "21       11      2   160  1744\n",
      "22        1      5   159  1980\n",
      "23        1      5   160  1980\n",
      "24        2      5   159  2029\n",
      "25        2      5   160  2029\n",
      "26        3      5   159  1478\n",
      "27        3      5   160  1476\n",
      "28        4      5   159  1620\n",
      "29        4      5   160  1596\n",
      "...     ...    ...   ...   ...\n",
      "1796      8    134   159  1120\n",
      "1797      8    134   160  1123\n",
      "1798      9    134   159  1214\n",
      "1799      9    134   160  1217\n",
      "1800     10    134   159  1668\n",
      "1801     10    134   160  1383\n",
      "1802     11    134   159  2031\n",
      "1803     11    134   160  2035\n",
      "1804      1    137   159  1980\n",
      "1805      1    137   160  1980\n",
      "1806      2    137   159  2021\n",
      "1807      2    137   160  2021\n",
      "1808      3    137   159  1543\n",
      "1809      3    137   160  1599\n",
      "1810      4    137   159  1667\n",
      "1811      4    137   160  1648\n",
      "1812      5    137   159  2381\n",
      "1813      5    137   160  2381\n",
      "1814      6    137   159  1692\n",
      "1815      6    137   160  1629\n",
      "1816      7    137   159  1474\n",
      "1817      7    137   160  1474\n",
      "1818      8    137   159  1287\n",
      "1819      8    137   160  1358\n",
      "1820      9    137   159  1165\n",
      "1821      9    137   160  1166\n",
      "1822     10    137   159  1850\n",
      "1823     10    137   160  1845\n",
      "1824     11    137   159  2018\n",
      "1825     11    137   160  2035\n",
      "\n",
      "[1826 rows x 4 columns]\n",
      "\n",
      "\n",
      "MAPE of current round is 64.79943506228236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and predict for all forecast rounds\n",
    "pred_all = []\n",
    "metric_all = []\n",
    "for r in range(bs.NUM_ROUNDS): \n",
    "    print('---- Round ' + str(r+1) + ' ----')\n",
    "    train_df = pd.read_csv(os.path.join(TRAIN_DIR, 'train_round_'+str(r+1)+'.csv'))\n",
    "    train_df['move'] = train_df['logmove'].apply(lambda x: round(math.exp(x)))\n",
    "    train_df.drop('logmove', axis=1, inplace=True)\n",
    "    print(train_df.head(3))\n",
    "    print('')\n",
    "    # Fill missing values\n",
    "    store_list = train_df['store'].unique()\n",
    "    brand_list = train_df['brand'].unique()\n",
    "    week_list = range(bs.TRAIN_START_WEEK, bs.TEST_END_WEEK_LIST[r]+1)\n",
    "    d = {'store': store_list,\n",
    "         'brand': brand_list,\n",
    "         'week': week_list}        \n",
    "    data_grid = df_from_cartesian_product(d)\n",
    "    data_filled = pd.merge(data_grid, train_df, how='left', \n",
    "                            on=['store', 'brand', 'week'])\n",
    "    print('Number of missing rows is {}'.format(data_filled[data_filled.isnull().any(axis=1)].shape[0]))\n",
    "    print('')\n",
    "    data_filled = data_filled.groupby(['store', 'brand']). \\\n",
    "                              apply(lambda x: x.fillna(method='ffill').fillna(method='bfill'))\n",
    "    # Create datetime features\n",
    "    data_filled['week_start'] = data_filled['week'].apply(lambda x: first_week_start + datetime.timedelta(days=(x-bs.TRAIN_START_WEEK)*7))\n",
    "    data_filled['year'] = data_filled['week_start'].apply(lambda x: x.year)\n",
    "    data_filled['month'] = data_filled['week_start'].apply(lambda x: x.month)\n",
    "    data_filled['week_of_month'] = data_filled['week_start'].apply(lambda x: week_of_month(x))\n",
    "    data_filled['day'] = data_filled['week_start'].apply(lambda x: x.day)\n",
    "    data_filled.drop('week_start', axis=1, inplace=True)\n",
    "    # Create other features (lagged features, moving averages, etc.)\n",
    "    features = data_filled.groupby(['store','brand']). \\\n",
    "                           apply(lambda x: create_features(x))\n",
    "    train_fea = features[features.week <= bs.TRAIN_END_WEEK_LIST[r]].reset_index(drop=True)\n",
    "    # Drop rows with NaN values\n",
    "    train_fea.dropna(inplace=True)\n",
    "    print(train_fea.head(1))\n",
    "    print('')\n",
    "    print('Training and predicting models...')\n",
    "    evals_result = {} # to record eval results for plotting\n",
    "    dtrain = lgb.Dataset(\n",
    "                train_fea.drop('move', axis=1, inplace=False), \n",
    "                label = train_fea['move']\n",
    "    )\n",
    "    # Train GBM model\n",
    "    bst = lgb.train(\n",
    "        params, \n",
    "        dtrain, \n",
    "        num_boost_round = MAX_ROUNDS,\n",
    "        valid_sets = [dtrain], \n",
    "        categorical_feature = categ_fea,\n",
    "        early_stopping_rounds = 125, \n",
    "        evals_result = evals_result,\n",
    "        verbose_eval = 20\n",
    "    )\n",
    "    # Generate forecasts\n",
    "    test_fea = features[features.week >= bs.TEST_START_WEEK_LIST[r]].reset_index(drop=True)\n",
    "    pred = test_fea.groupby(['store','brand']). \\\n",
    "                    apply(lambda x: make_predictions(x, bst)). \\\n",
    "                    reset_index(drop=True)\n",
    "            \n",
    "    print(pred)\n",
    "    print('')\n",
    "    # Evaluate prediction accuracy\n",
    "    test_df = pd.read_csv(os.path.join(TEST_DIR, 'test_round_'+str(r+1)+'.csv'))\n",
    "    test_df['move'] = test_df['logmove'].apply(lambda x: round(math.exp(x)))\n",
    "    test_df.drop('logmove', axis=1, inplace=True)\n",
    "    metric_value = evaluate(pred, test_df)\n",
    "    print('')\n",
    "    print('MAPE of current round is {}'.format(metric_value))\n",
    "    print('')\n",
    "    # Keep the predictions and accuracy\n",
    "    pred_all.append(pred)\n",
    "    metric_all.append(metric_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.8627763644255"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(metric_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot feature importances...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9bdc3053c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Plot feature importances...')\n",
    "ax = lgb.plot_importance(bst, max_num_features=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
