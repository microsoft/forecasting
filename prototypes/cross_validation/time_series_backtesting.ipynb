{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Backtesting using HyperDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "In order to run this notebook, you need to install AML SDK and its widget extension in your environment by running the following commands in commandline or terminal.  \n",
    "First, you need to activate your environment by running `activate <your env>` or `source activate <your env>`(on Linux).   \n",
    "`pip install --upgrade azureml-sdk[notebooks,automl]`  \n",
    "`jupyter nbextension install --py --user azureml.train.widgets`  \n",
    "`jupyter nbextension enable --py --user azureml.train.widgets`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\hlu\\TSPerf\\prototypes\\cross_validation\\amlsdk\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name = 'tsbacktest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate script locally\n",
    "Configure local, user managed environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "run_config_user_managed.environment.python.interpreter_path = 'C:/Anaconda/envs/tsperf/python.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory='./', \n",
    "                      script='train_validation.py', \n",
    "                      arguments=['--data-folder', 'C:/Users/hlu/TSPerf/prototypes/cross_validation/data/', '--n-estimators', '10', '--min-samples-split', '10'],\n",
    "                      run_config=run_config_user_managed)\n",
    "run_local = exp.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 193.81733289262013}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_local.get_details()\n",
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a single job to BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Batch AI cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target hlutsperfnew, just use it.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<azureml.core.compute.batchai.BatchAiCompute at 0x1196ef35da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "batchai_cluster_name = \"hlutsperfnew\"\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name = batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=0, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize()) \n",
    "    \n",
    "# BatchAiCompute.attach(workspace=ws,\n",
    "#                       name=\"hlutsperfnew\",\n",
    "#                       resource_id=\"/subscriptions/ff18d7a8-962a-406c-858f-49acd23d6c01/resourceGroups/hluamlsdkrg/providers/Microsoft.BatchAI/workspaces/hlutsperf5f5171588c9/clusters/hlutsperf5f5171588c9\")\n",
    "\n",
    "# for ct in ws.compute_targets():\n",
    "#     print(ct.name, ct.type, ct.provisioning_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'numpy', 'scikit-garden', 'joblib'],\n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ws.get_default_datastore().as_mount(),\n",
    "    '--n-estimators': 10,\n",
    "    '--min-samples-split': 10\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validation.py',\n",
    "                environment_definition=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_batchai = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa215caf9d8428b83246d4515e97b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRun()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run_batchai).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 193.81733289262013}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_details()\n",
    "run_batchai.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyper parameter using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The same input parameter(s) are specified in estimator script params and HyperDrive parameter space. HyperDrive parameter space definition will override duplicate entries in estimator. ['--n-estimators', '--min-samples-split'] is the list of overridden parameter(s).\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "ps = RandomParameterSampling({\n",
    "    '--min-samples-split': choice(5, 10),\n",
    "    '--n-estimators': choice(10, 100)\n",
    "})\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='average pinball loss', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=8,\n",
    "                          max_concurrent_runs=4)\n",
    "htr = exp.submit(config=htc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9058489b77145de88c94204812db65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_HyperDrive(widget_settings={'childWidgetDisplay': 'popup'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(htr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data-folder', '$AZUREML_DATAREFERENCE_workspacefilestore', '--min-samples-split', '5', '--n-estimators', '10']\n"
     ]
    }
   ],
   "source": [
    "best_run = htr.get_best_run_by_primary_metric()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "print(parameter_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use custom Docker image\n",
    "**Note**: This part is not working yet. Will update the this section later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore='./', \n",
    "                   mode='mount',\n",
    "                   overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "\n",
    "cd_config = RunConfiguration()\n",
    "cd_config.target = compute_target.name\n",
    "cd_config.environment.python.user_managed_dependencies = True\n",
    "cd_config.environment.python.interpreter_path = '/opt/conda/envs/tsperf/python.exe' \n",
    "\n",
    "cd_config.environment.docker.enabled = True\n",
    "cd_config.environment.docker.base_image = 'hluamlwsnew6345184683.azurecr.io/energy_load/gefcom2017_d_prob_mt_hourly/baseline_image:latest'\n",
    "#cd_config.data_references = {ds.name: dr}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: tsbacktest_1538597400733\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "Logging into Docker registry: hluamlwsnew6345184683.azurecr.io\n",
      "Login Succeeded\n",
      "Docker login(s) took 1.0006158351898193 seconds\n",
      "Building image with name hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059\n",
      "Sending build context to Docker daemon  179.7kB\n",
      "\n",
      "Step 1/8 : FROM hluamlwsnew6345184683.azurecr.io/energy_load/gefcom2017_d_prob_mt_hourly/baseline_image:latest\n",
      "latest: Pulling from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "f2c09775d936: Pulling fs layer\n",
      "ea9cd93e7c9a: Pulling fs layer\n",
      "05cd9f5f996c: Pulling fs layer\n",
      "c643890f7c78: Pulling fs layer\n",
      "d1fca452aef5: Pulling fs layer\n",
      "2c21aa30b7a3: Pulling fs layer\n",
      "804b51d41a46: Pulling fs layer\n",
      "20e5e93a5f33: Pulling fs layer\n",
      "678ca7051f72: Pulling fs layer\n",
      "193194d48ad3: Pulling fs layer\n",
      "d7052edc805e: Pulling fs layer\n",
      "bd317a6832fb: Pulling fs layer\n",
      "f0fc1d0bf4d3: Pulling fs layer\n",
      "0bb481ebb087: Pulling fs layer\n",
      "077dce99a933: Pulling fs layer\n",
      "9c9cfcfd445a: Pulling fs layer\n",
      "83315bfe4d78: Pulling fs layer\n",
      "3f0e9d05a94b: Pulling fs layer\n",
      "d3476ebf533f: Pulling fs layer\n",
      "25b749158585: Pulling fs layer\n",
      "bf19d8b549c7: Pulling fs layer\n",
      "c643890f7c78: Waiting\n",
      "d1fca452aef5: Waiting\n",
      "2c21aa30b7a3: Waiting\n",
      "804b51d41a46: Waiting\n",
      "20e5e93a5f33: Waiting\n",
      "678ca7051f72: Waiting\n",
      "193194d48ad3: Waiting\n",
      "bd317a6832fb: Waiting\n",
      "f0fc1d0bf4d3: Waiting\n",
      "0bb481ebb087: Waiting\n",
      "077dce99a933: Waiting\n",
      "9c9cfcfd445a: Waiting\n",
      "83315bfe4d78: Waiting\n",
      "3f0e9d05a94b: Waiting\n",
      "d3476ebf533f: Waiting\n",
      "25b749158585: Waiting\n",
      "bf19d8b549c7: Waiting\n",
      "d7052edc805e: Waiting\n",
      "ea9cd93e7c9a: Verifying Checksum\n",
      "ea9cd93e7c9a: Download complete\n",
      "f2c09775d936: Verifying Checksum\n",
      "f2c09775d936: Download complete\n",
      "c643890f7c78: Verifying Checksum\n",
      "c643890f7c78: Download complete\n",
      "d1fca452aef5: Verifying Checksum\n",
      "d1fca452aef5: Download complete\n",
      "f2c09775d936: Pull complete\n",
      "2c21aa30b7a3: Verifying Checksum\n",
      "2c21aa30b7a3: Download complete\n",
      "ea9cd93e7c9a: Pull complete\n",
      "804b51d41a46: Verifying Checksum\n",
      "804b51d41a46: Download complete\n",
      "20e5e93a5f33: Verifying Checksum\n",
      "20e5e93a5f33: Download complete\n",
      "678ca7051f72: Verifying Checksum\n",
      "678ca7051f72: Download complete\n",
      "05cd9f5f996c: Verifying Checksum\n",
      "05cd9f5f996c: Download complete\n",
      "d7052edc805e: Verifying Checksum\n",
      "d7052edc805e: Download complete\n",
      "f0fc1d0bf4d3: Verifying Checksum\n",
      "f0fc1d0bf4d3: Download complete\n",
      "bd317a6832fb: Verifying Checksum\n",
      "bd317a6832fb: Download complete\n",
      "077dce99a933: Verifying Checksum\n",
      "077dce99a933: Download complete\n",
      "9c9cfcfd445a: Verifying Checksum\n",
      "9c9cfcfd445a: Download complete\n",
      "83315bfe4d78: Verifying Checksum\n",
      "83315bfe4d78: Download complete\n",
      "0bb481ebb087: Verifying Checksum\n",
      "0bb481ebb087: Download complete\n",
      "d3476ebf533f: Verifying Checksum\n",
      "d3476ebf533f: Download complete\n",
      "25b749158585: Verifying Checksum\n",
      "25b749158585: Download complete\n",
      "3f0e9d05a94b: Verifying Checksum\n",
      "3f0e9d05a94b: Download complete\n",
      "193194d48ad3: Verifying Checksum\n",
      "193194d48ad3: Download complete\n",
      "bf19d8b549c7: Verifying Checksum\n",
      "bf19d8b549c7: Download complete\n",
      "05cd9f5f996c: Pull complete\n",
      "c643890f7c78: Pull complete\n",
      "d1fca452aef5: Pull complete\n",
      "2c21aa30b7a3: Pull complete\n",
      "804b51d41a46: Pull complete\n",
      "20e5e93a5f33: Pull complete\n",
      "678ca7051f72: Pull complete\n",
      "193194d48ad3: Pull complete\n",
      "d7052edc805e: Pull complete\n",
      "bd317a6832fb: Pull complete\n",
      "f0fc1d0bf4d3: Pull complete\n",
      "0bb481ebb087: Pull complete\n",
      "077dce99a933: Pull complete\n",
      "9c9cfcfd445a: Pull complete\n",
      "83315bfe4d78: Pull complete\n",
      "3f0e9d05a94b: Pull complete\n",
      "d3476ebf533f: Pull complete\n",
      "25b749158585: Pull complete\n",
      "bf19d8b549c7: Pull complete\n",
      "Digest: sha256:cc5476f7311a0baeef551582cf737ded5c5ddfbc4653b9e29114b6241b9f26a0\n",
      "Status: Downloaded newer image for hluamlwsnew6345184683.azurecr.io/energy_load/gefcom2017_d_prob_mt_hourly/baseline_image:latest\n",
      " ---> d7fc4311986a\n",
      "Step 2/8 : USER root\n",
      " ---> Running in be1bc883e510\n",
      " ---> fdfaf170eb41\n",
      "Removing intermediate container be1bc883e510\n",
      "Step 3/8 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in d58f2724c609\n",
      " ---> f2a48f9c4b50\n",
      "Removing intermediate container d58f2724c609\n",
      "Step 4/8 : WORKDIR /\n",
      " ---> a0ecadc67070\n",
      "Removing intermediate container 42c958095161\n",
      "Step 5/8 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 4eebde6bbf40\n",
      "Step 6/8 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> 5aeb608b4942\n",
      "Step 7/8 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" \"--conf\" \"spark.app.name=Azure ML Experiment\" \"--conf\" \"spark.yarn.maxAppAttempts=1\" \"--driver-java-options\" \"-Dlog4j.configuration=file:./azureml-setup/log4j.properties\" \"--conf\" \"spark.eventLog.enabled=true\" \"--conf\" \"spark.eventLog.dir=./azureml-logs\" /azureml-setup/spark_cache.py'; fi\n",
      " ---> Running in 59f1faf4e918\n",
      " ---> 73ed09d32c13\n",
      "Removing intermediate container 59f1faf4e918\n",
      "Step 8/8 : CMD bash\n",
      " ---> Running in 0ccdb4f825ac\n",
      " ---> 203252835baa\n",
      "Removing intermediate container 0ccdb4f825ac\n",
      "Successfully built 203252835baa\n",
      "Successfully tagged hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059:latest\n",
      "Removing any dangling images\n",
      "Docker build took 216.83555221557617 seconds\n",
      "Logging into acr hluamlwsnew6345184683.azurecr.io to do docker push\n",
      "Login Succeeded\n",
      "Pushing image azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059 to acr hluamlwsnew6345184683.azurecr.io\n",
      "The push refers to a repository [hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059]\n",
      "4d435267268e: Preparing\n",
      "ac14964ff84b: Preparing\n",
      "08bced6b9899: Preparing\n",
      "51e76290ae10: Preparing\n",
      "8844728555b8: Preparing\n",
      "95f5198c0335: Preparing\n",
      "0982042b3924: Preparing\n",
      "bab69e5a7ea4: Preparing\n",
      "636ec4ae4056: Preparing\n",
      "50a12c0409c8: Preparing\n",
      "0b5da47507a7: Preparing\n",
      "073fcbe01022: Preparing\n",
      "f33bb4dbdd54: Preparing\n",
      "e1b2bed244cc: Preparing\n",
      "26d520f6efeb: Preparing\n",
      "19c6d28eca56: Preparing\n",
      "255ae21d1017: Preparing\n",
      "331aff62d7c1: Preparing\n",
      "6d42ca4f98da: Preparing\n",
      "2df1bfdb896c: Preparing\n",
      "ca173dc10e31: Preparing\n",
      "54e10c08a841: Preparing\n",
      "1f09b1beaa90: Preparing\n",
      "9e63c5bce458: Preparing\n",
      "95f5198c0335: Waiting\n",
      "0982042b3924: Waiting\n",
      "bab69e5a7ea4: Waiting\n",
      "636ec4ae4056: Waiting\n",
      "50a12c0409c8: Waiting\n",
      "0b5da47507a7: Waiting\n",
      "073fcbe01022: Waiting\n",
      "f33bb4dbdd54: Waiting\n",
      "e1b2bed244cc: Waiting\n",
      "26d520f6efeb: Waiting\n",
      "19c6d28eca56: Waiting\n",
      "255ae21d1017: Waiting\n",
      "331aff62d7c1: Waiting\n",
      "6d42ca4f98da: Waiting\n",
      "2df1bfdb896c: Waiting\n",
      "ca173dc10e31: Waiting\n",
      "54e10c08a841: Waiting\n",
      "1f09b1beaa90: Waiting\n",
      "9e63c5bce458: Waiting\n",
      "8844728555b8: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "51e76290ae10: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "4d435267268e: Pushed\n",
      "ac14964ff84b: Pushed\n",
      "95f5198c0335: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "0982042b3924: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "08bced6b9899: Pushed\n",
      "bab69e5a7ea4: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "636ec4ae4056: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "0b5da47507a7: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "073fcbe01022: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "e1b2bed244cc: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "26d520f6efeb: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "255ae21d1017: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "19c6d28eca56: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "50a12c0409c8: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "f33bb4dbdd54: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "331aff62d7c1: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "6d42ca4f98da: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "2df1bfdb896c: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "54e10c08a841: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "ca173dc10e31: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "1f09b1beaa90: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n",
      "9e63c5bce458: Mounted from energy_load/gefcom2017_d_prob_mt_hourly/baseline_image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest: digest: sha256:4e647780f23b8dcb077770bf3c02e505fdee0f793cc13d8a4c51a0b4c61264fd size: 5358\n",
      "Removing login credentials for hluamlwsnew6345184683.azurecr.io\n",
      "Docker push took 54.86982989311218 seconds\n",
      "Not logged in to hluamlwsnew6345184683.azurecr.io\n",
      "Docker logout(s) took 0.012404441833496094 seconds\n",
      "Removing image with name hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059\n",
      "Untagged: hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059:latest\n",
      "Untagged: hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059@sha256:4e647780f23b8dcb077770bf3c02e505fdee0f793cc13d8a4c51a0b4c61264fd\n",
      "Deleted: sha256:203252835baaaf06e71b7d92f4777d58361e373d0f6557b2b7b99c1cfc4feb51\n",
      "Deleted: sha256:73ed09d32c1307f07b8bc1ddfc8495521c95490a73a61f82348c1165e6b9a866\n",
      "Deleted: sha256:5aeb608b49428d45e195e5b90af0fa6c45056dbcc7b14ce5438ed7cb86d3b9e1\n",
      "Deleted: sha256:eebdaaffa0075b4d29eb6f49c8d743198865a4e043458cf065fe51f4202ccfef\n",
      "Deleted: sha256:4eebde6bbf402f4af1c9718c0d7aaefa08e21f4e877c61c4dc2e360b201b9149\n",
      "Deleted: sha256:c5e34efab65b104b011c0897ad156f58134b403dff54aaa0ec186989e4dc3bbc\n",
      "Deleted: sha256:a0ecadc670705f4a7ba88a892ba5bb442adccc60c6321bdc825e5a9bc3ee4119\n",
      "Deleted: sha256:f2a48f9c4b50ffb43293ea0e65580c09a432fd72114bc6f3657ec28f2110e700\n",
      "Deleted: sha256:c131e49bba561316e2e7ee7430133a3a36b807a4ab450a1908377691d3e7a677\n",
      "Deleted: sha256:fdfaf170eb41c80947b5ea287e8509fba87498964c5697ec1c903bc27d02d870\n",
      "Total task took 272.7581684589386 secs\n",
      "\n",
      "Streaming azureml-logs/55_batchai_execution.txt\n",
      "===============================================\n",
      "\n",
      "2018-10-03T20:20:16Z Mounted //hluamlwsnew7391587880.file.core.windows.net/azureml at /mnt/batch/tasks/shared/LS_root/jobs/hlutsperfnew6ea0946834/azureml/tsbacktest_1538597400733/mounts/azureml_project_share\n",
      "2018-10-03T20:20:16Z No blob file systems configured\n",
      "2018-10-03T20:20:16Z No unmanaged file systems configured\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059\n",
      "f2c09775d936: Pulling fs layer\n",
      "ea9cd93e7c9a: Pulling fs layer\n",
      "05cd9f5f996c: Pulling fs layer\n",
      "c643890f7c78: Pulling fs layer\n",
      "d1fca452aef5: Pulling fs layer\n",
      "2c21aa30b7a3: Pulling fs layer\n",
      "804b51d41a46: Pulling fs layer\n",
      "20e5e93a5f33: Pulling fs layer\n",
      "678ca7051f72: Pulling fs layer\n",
      "193194d48ad3: Pulling fs layer\n",
      "d7052edc805e: Pulling fs layer\n",
      "bd317a6832fb: Pulling fs layer\n",
      "f0fc1d0bf4d3: Pulling fs layer\n",
      "0bb481ebb087: Pulling fs layer\n",
      "077dce99a933: Pulling fs layer\n",
      "9c9cfcfd445a: Pulling fs layer\n",
      "83315bfe4d78: Pulling fs layer\n",
      "3f0e9d05a94b: Pulling fs layer\n",
      "d3476ebf533f: Pulling fs layer\n",
      "25b749158585: Pulling fs layer\n",
      "bf19d8b549c7: Pulling fs layer\n",
      "5454acb80b44: Pulling fs layer\n",
      "5c6023b12604: Pulling fs layer\n",
      "d2b2bd83214b: Pulling fs layer\n",
      "f0fc1d0bf4d3: Waiting\n",
      "0bb481ebb087: Waiting\n",
      "077dce99a933: Waiting\n",
      "9c9cfcfd445a: Waiting\n",
      "83315bfe4d78: Waiting\n",
      "3f0e9d05a94b: Waiting\n",
      "d3476ebf533f: Waiting\n",
      "25b749158585: Waiting\n",
      "bf19d8b549c7: Waiting\n",
      "5454acb80b44: Waiting\n",
      "5c6023b12604: Waiting\n",
      "c643890f7c78: Waiting\n",
      "d2b2bd83214b: Waiting\n",
      "d1fca452aef5: Waiting\n",
      "2c21aa30b7a3: Waiting\n",
      "193194d48ad3: Waiting\n",
      "d7052edc805e: Waiting\n",
      "804b51d41a46: Waiting\n",
      "bd317a6832fb: Waiting\n",
      "678ca7051f72: Waiting\n",
      "20e5e93a5f33: Waiting\n",
      "f2c09775d936: Verifying Checksum\n",
      "f2c09775d936: Download complete\n",
      "ea9cd93e7c9a: Verifying Checksum\n",
      "ea9cd93e7c9a: Download complete\n",
      "c643890f7c78: Verifying Checksum\n",
      "c643890f7c78: Download complete\n",
      "2c21aa30b7a3: Verifying Checksum\n",
      "2c21aa30b7a3: Download complete\n",
      "d1fca452aef5: Verifying Checksum\n",
      "d1fca452aef5: Download complete\n",
      "20e5e93a5f33: Verifying Checksum\n",
      "20e5e93a5f33: Download complete\n",
      "678ca7051f72: Verifying Checksum\n",
      "678ca7051f72: Download complete\n",
      "804b51d41a46: Verifying Checksum\n",
      "804b51d41a46: Download complete\n",
      "d7052edc805e: Verifying Checksum\n",
      "d7052edc805e: Download complete\n",
      "bd317a6832fb: Verifying Checksum\n",
      "bd317a6832fb: Download complete\n",
      "f0fc1d0bf4d3: Verifying Checksum\n",
      "f0fc1d0bf4d3: Download complete\n",
      "0bb481ebb087: Verifying Checksum\n",
      "0bb481ebb087: Download complete\n",
      "05cd9f5f996c: Verifying Checksum\n",
      "05cd9f5f996c: Download complete\n",
      "9c9cfcfd445a: Download complete\n",
      "83315bfe4d78: Verifying Checksum\n",
      "83315bfe4d78: Download complete\n",
      "3f0e9d05a94b: Verifying Checksum\n",
      "3f0e9d05a94b: Download complete\n",
      "d3476ebf533f: Verifying Checksum\n",
      "d3476ebf533f: Download complete\n",
      "25b749158585: Verifying Checksum\n",
      "25b749158585: Download complete\n",
      "077dce99a933: Verifying Checksum\n",
      "077dce99a933: Download complete\n",
      "5454acb80b44: Verifying Checksum\n",
      "5454acb80b44: Download complete\n",
      "5c6023b12604: Download complete\n",
      "d2b2bd83214b: Download complete\n",
      "bf19d8b549c7: Verifying Checksum\n",
      "bf19d8b549c7: Download complete\n",
      "193194d48ad3: Verifying Checksum\n",
      "193194d48ad3: Download complete\n",
      "f2c09775d936: Pull complete\n",
      "ea9cd93e7c9a: Pull complete\n",
      "05cd9f5f996c: Pull complete\n",
      "c643890f7c78: Pull complete\n",
      "d1fca452aef5: Pull complete\n",
      "2c21aa30b7a3: Pull complete\n",
      "804b51d41a46: Pull complete\n",
      "20e5e93a5f33: Pull complete\n",
      "678ca7051f72: Pull complete\n",
      "193194d48ad3: Pull complete\n",
      "d7052edc805e: Pull complete\n",
      "bd317a6832fb: Pull complete\n",
      "f0fc1d0bf4d3: Pull complete\n",
      "0bb481ebb087: Pull complete\n",
      "077dce99a933: Pull complete\n",
      "9c9cfcfd445a: Pull complete\n",
      "83315bfe4d78: Pull complete\n",
      "3f0e9d05a94b: Pull complete\n",
      "d3476ebf533f: Pull complete\n",
      "25b749158585: Pull complete\n",
      "bf19d8b549c7: Pull complete\n",
      "5454acb80b44: Pull complete\n",
      "5c6023b12604: Pull complete\n",
      "d2b2bd83214b: Pull complete\n",
      "Digest: sha256:4e647780f23b8dcb077770bf3c02e505fdee0f793cc13d8a4c51a0b4c61264fd\n",
      "Status: Downloaded newer image for hluamlwsnew6345184683.azurecr.io/azureml/azureml_fde5d5625ce4487e7bc0ad5cd08e0059:latest\n",
      "2018-10-03T20:25:16Z Error: Infiniband is enabled but RDMA device is not able to find\n",
      "7593520199d5826f4b2e70b6bcdbc62618af6f9d7e50860de78d8a26cb3d0e12\n",
      "Error response from daemon: Container 7593520199d5826f4b2e70b6bcdbc62618af6f9d7e50860de78d8a26cb3d0e12 is not running\n",
      "2018-10-03T20:25:40Z removing container tsbacktest_1538597400733 exited with 0\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: tsbacktest_1538597400733\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'tsbacktest_1538597400733',\n",
       " 'target': 'hlutsperfnew',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2018-10-03T20:15:25.003653Z',\n",
       " 'endTimeUtc': '2018-10-03T20:25:45.397781Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'a9b75a15-9cf5-4622-87fb-a72e16ce3bcf'},\n",
       " 'runDefinition': {'Script': 'train_validation.py',\n",
       "  'Arguments': [],\n",
       "  'Framework': 0,\n",
       "  'Target': 'hlutsperfnew',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'Environment': {'Python': {'InterpreterPath': '/opt/conda/envs/tsperf/python.exe',\n",
       "    'UserManagedDependencies': True,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}]},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'hluamlwsnew6345184683.azurecr.io/energy_load/gefcom2017_d_prob_mt_hourly/baseline_image:latest',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 1, 'MemoryGb': 4},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1538597400733/azureml-logs/20_image_build_log.txt?sv=2017-04-17&sr=b&sig=wmJRhsDsLSVgwkdzzKFZEluhpd5scpvZ3HyhKkmbSEc%3D&st=2018-10-03T20%3A15%3A46Z&se=2018-10-04T04%3A25%3A46Z&sp=r',\n",
       "  'azureml-logs/55_batchai_execution.txt': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1538597400733/azureml-logs/55_batchai_execution.txt?sv=2017-04-17&sr=b&sig=JsP8aV1aZs91L%2BMqY9tvzf3AgaHL9KicWsu0lBjKH1Y%3D&st=2018-10-03T20%3A15%3A46Z&se=2018-10-04T04%3A25%3A46Z&sp=r'}}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = ScriptRunConfig('./', './train_validation.py', \n",
    "                      #arguments=['--data-folder', ds.as_mount(), '--n-estimators', '10', '--min-samples-split', '10'],\n",
    "                      run_config=cd_config)\n",
    "\n",
    "run = exp.submit(config=src)\n",
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TrainingException",
     "evalue": "{\n    \"error_details\": {\n        \"correlation\": {\n            \"operation\": \"bccee4f3-4fa534a7ee234d35\",\n            \"request\": \"I5sZu/220ic=\"\n        },\n        \"error\": {\n            \"code\": \"UserError\",\n            \"debugInfo\": {\n                \"innerException\": {\n                    \"innerException\": {\n                        \"message\": \"Could not cast or convert from System.String to Microsoft.MachineLearning.Execution.Contracts.ContainerRegistry.\",\n                        \"stackTrace\": \"   at Newtonsoft.Json.Utilities.ConvertUtils.EnsureTypeAssignable(Object value, Type initialType, Type targetType)\\n   at Newtonsoft.Json.Utilities.ConvertUtils.ConvertOrCast(Object initialValue, CultureInfo culture, Type targetType)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.EnsureType(JsonReader reader, Object value, CultureInfo culture, JsonContract contract, Type targetType)\",\n                        \"type\": \"System.ArgumentException\"\n                    },\n                    \"message\": \"Error converting value \\\"hluamlwsnew6345184683.azurecr.io\\\" to type 'Microsoft.MachineLearning.Execution.Contracts.ContainerRegistry'. Path 'Configuration.environment.docker.baseImageRegistry', line 1, position 833.\",\n                    \"stackTrace\": \"   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.EnsureType(JsonReader reader, Object value, CultureInfo culture, JsonContract contract, Type targetType)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.Deserialize(JsonReader reader, Type objectType, Boolean checkAdditionalContent)\\n   at Newtonsoft.Json.JsonSerializer.DeserializeInternal(JsonReader reader, Type objectType)\\n   at Newtonsoft.Json.JsonSerializer.Deserialize[T](JsonReader reader)\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.ParseRunDefinitionFromFormFile(IFormFile file) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 565\",\n                    \"type\": \"Newtonsoft.Json.JsonSerializationException\"\n                },\n                \"message\": \"Failed to deserialize run definition\",\n                \"stackTrace\": \"   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.ParseRunDefinitionFromFormFile(IFormFile file) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 572\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.StartRun(Guid subscriptionId, String resourceGroupName, String workspaceName, String experimentName, ICollection`1 files, String runId) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 188\\n   at lambda_method(Closure , Object )\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\n                \"type\": \"Microsoft.MachineLearning.Common.WebApi.Exceptions.BadRequestException\"\n            },\n            \"message\": \"Failed to deserialize run definition\"\n        }\n    },\n    \"status_code\": 400,\n    \"url\": \"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/ff18d7a8-962a-406c-858f-49acd23d6c01/resourceGroups/hluamlsdkrg/providers/Microsoft.MachineLearningServices/workspaces/hluamlwsnew/experiments/tsbacktest/run\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTrainingException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-65a6f38f68ff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mrun_batchai\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mrun_batchai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tsperf\\lib\\site-packages\\azureml\\core\\experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[1;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"submit config {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mrun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[0mrun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tsperf\\lib\\site-packages\\azureml\\train\\estimator.py\u001b[0m in \u001b[0;36m_estimator_submit_method\u001b[1;34m(estimator, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m             inputs=inputs)\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[0mexperiment_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0moverride_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tsperf\\lib\\site-packages\\azureml\\train\\estimator.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, workspace, experiment_name)\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_submitted_runconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtelemetry_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_override_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\envs\\tsperf\\lib\\site-packages\\azureml\\train\\estimator.py\u001b[0m in \u001b[0;36m_submit\u001b[1;34m(self, workspace, experiment_name, telemetry_values)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mexperiment_run\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAzureMLException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTrainingException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minner_exception\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTrainingException\u001b[0m: {\n    \"error_details\": {\n        \"correlation\": {\n            \"operation\": \"bccee4f3-4fa534a7ee234d35\",\n            \"request\": \"I5sZu/220ic=\"\n        },\n        \"error\": {\n            \"code\": \"UserError\",\n            \"debugInfo\": {\n                \"innerException\": {\n                    \"innerException\": {\n                        \"message\": \"Could not cast or convert from System.String to Microsoft.MachineLearning.Execution.Contracts.ContainerRegistry.\",\n                        \"stackTrace\": \"   at Newtonsoft.Json.Utilities.ConvertUtils.EnsureTypeAssignable(Object value, Type initialType, Type targetType)\\n   at Newtonsoft.Json.Utilities.ConvertUtils.ConvertOrCast(Object initialValue, CultureInfo culture, Type targetType)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.EnsureType(JsonReader reader, Object value, CultureInfo culture, JsonContract contract, Type targetType)\",\n                        \"type\": \"System.ArgumentException\"\n                    },\n                    \"message\": \"Error converting value \\\"hluamlwsnew6345184683.azurecr.io\\\" to type 'Microsoft.MachineLearning.Execution.Contracts.ContainerRegistry'. Path 'Configuration.environment.docker.baseImageRegistry', line 1, position 833.\",\n                    \"stackTrace\": \"   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.EnsureType(JsonReader reader, Object value, CultureInfo culture, JsonContract contract, Type targetType)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.SetPropertyValue(JsonProperty property, JsonConverter propertyConverter, JsonContainerContract containerContract, JsonProperty containerProperty, JsonReader reader, Object target)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.PopulateObject(Object newObject, JsonReader reader, JsonObjectContract contract, JsonProperty member, String id)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.CreateObject(JsonReader reader, Type objectType, JsonContract contract, JsonProperty member, JsonContainerContract containerContract, JsonProperty containerMember, Object existingValue)\\n   at Newtonsoft.Json.Serialization.JsonSerializerInternalReader.Deserialize(JsonReader reader, Type objectType, Boolean checkAdditionalContent)\\n   at Newtonsoft.Json.JsonSerializer.DeserializeInternal(JsonReader reader, Type objectType)\\n   at Newtonsoft.Json.JsonSerializer.Deserialize[T](JsonReader reader)\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.ParseRunDefinitionFromFormFile(IFormFile file) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 565\",\n                    \"type\": \"Newtonsoft.Json.JsonSerializationException\"\n                },\n                \"message\": \"Failed to deserialize run definition\",\n                \"stackTrace\": \"   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.ParseRunDefinitionFromFormFile(IFormFile file) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 572\\n   at Microsoft.MachineLearning.Execution.EntryPoints.Api.Controllers.ExecutionController.StartRun(Guid subscriptionId, String resourceGroupName, String workspaceName, String experimentName, ICollection`1 files, String runId) in /home/vsts/work/1/s/src/azureml-api/src/Execution/EntryPoints/Api/Controllers/ExecutionController.cs:line 188\\n   at lambda_method(Closure , Object )\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)\\n   at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync()\\n   at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextExceptionFilterAsync()\",\n                \"type\": \"Microsoft.MachineLearning.Common.WebApi.Exceptions.BadRequestException\"\n            },\n            \"message\": \"Failed to deserialize run definition\"\n        }\n    },\n    \"status_code\": 400,\n    \"url\": \"https://southcentralus.experiments.azureml.net/execution/v1.0/subscriptions/ff18d7a8-962a-406c-858f-49acd23d6c01/resourceGroups/hluamlsdkrg/providers/Microsoft.MachineLearningServices/workspaces/hluamlwsnew/experiments/tsbacktest/run\"\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "env_custom_docker = EnvironmentDefinition()\n",
    "\n",
    "env_custom_docker.python.user_managed_dependencies = True\n",
    "env_custom_docker.python.interpreter_path = '/opt/conda/envs/tsperf/python.exe' \n",
    "\n",
    "env_custom_docker.docker.enabled = True\n",
    "# env_custom_docker.docker.base_image_registry = 'hluamlwsnew6345184683.azurecr.io'\n",
    "env_custom_docker.docker.base_image = 'hluamlwsnew6345184683.azurecr.io/energy_load/gefcom2017_d_prob_mt_hourly/baseline_image:latest'\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ws.get_default_datastore().as_mount(),\n",
    "    '--n-estimators': 10,\n",
    "    '--min-samples-split': 10\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validation.py',\n",
    "                environment_definition=env_custom_docker)\n",
    "\n",
    "\n",
    "run_batchai = exp.submit(config=est)\n",
    "\n",
    "run_batchai.get_details()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "tsperf",
   "language": "python",
   "name": "tsperf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
