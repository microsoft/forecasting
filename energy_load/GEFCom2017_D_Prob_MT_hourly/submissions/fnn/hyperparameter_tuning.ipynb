{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning of QRNN Models with AML SDK and HyperDrive\n",
    "\n",
    "This notebook performs hyperparameter tuning of QRNN models with AML SDK and HyperDrive. It selects the best model by cross validation using the training data in the 6 forecast round. Specifically, it splits the training data into sub-training data and validation data. Then, it trains QRNN models with different sets of hyperparameters using the sub-training data and evaluate the pinball loss of each model with the validation data. The set of hyperparameters which yield the best cross validation pinball loss will be used to train models and forecast energy load across all 6 forecast rounds.\n",
    "\n",
    "## Prerequisites\n",
    "To run this notebook, you need to install AML SDK and its widget extension in your environment by running the following commands in a terminal. Before running the commands, you need to activate your environment by executing `activate <your env>` or `source activate <your env>` in a Linux VM.   \n",
    "`pip3 install --upgrade azureml-sdk[notebooks,automl]`  \n",
    "`jupyter nbextension install --py --user azureml.train.widgets`  \n",
    "`jupyter nbextension enable --py --user azureml.train.widgets`  \n",
    "\n",
    "To add the environment to your Jupyter kernels, you can do python3 -m ipykernel install --name <your env>. Besides, you need to create an Azure ML workspace and its configuration file (config.json) by following the 00.configuration.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.0.8\n"
     ]
    }
   ],
   "source": [
    "import azureml\n",
    "from azureml.core import Workspace, Run\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "# Opt-in diagnostics for better experience of future releases\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace & Create an Azure ML Experiment\n",
    "\n",
    "Initialize a [Workspace](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#workspace) object from the existing workspace you created in the Prerequisites step. `Workspace.from_config()` below creates a workspace object from the details stored in `config.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/tsperfadmin/Projects/zhouf/energy_forecast_fnn_model_v1/TSPerf/energy_load/GEFCom2017_D_Prob_MT_hourly/submissions/fnn/config.json\n",
      "Workspace name: tsperfwszhouf\n",
      "Azure region: eastus\n",
      "Subscription id: 8dd18bd7-b9dc-4213-b367-cd6a7745bc88\n",
      "Resource group: tsperf03\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "exp = Experiment(workspace=ws, name='tune_qrnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script on AML Compute Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML Compute as compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. cpucompute\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name =  \"cpucompute\"\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 16\n",
    "\n",
    "vm_size = \"STANDARD_D3_V2\"\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'r-base', 'r-data.table', 'r-rjson', 'r-optparse', 'r-doparallel'],\n",
    "                                                         pip_packages=['azure-cli-core<2.0.55'], \n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload data to default datastore\n",
    "\n",
    "Upload the 6 round train data of Energy dataset to the workspace's default datastore, which will later be mounted on a AML Compute target for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob tsperfwszhouf2444925548 azureml-blobstore-43291b4b-78d3-4c1a-94db-cdd97cf840c4\n"
     ]
    }
   ],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading ./data/features/train/train_round_1.csv\n",
      "Uploading ./data/features/train/train_round_2.csv\n",
      "Uploading ./data/features/train/train_round_3.csv\n",
      "Uploading ./data/features/train/train_round_4.csv\n",
      "Uploading ./data/features/train/train_round_5.csv\n",
      "Uploading ./data/features/train/train_round_6.csv\n",
      "Uploaded ./data/features/train/train_round_1.csv, 1 files out of an estimated total of 6\n",
      "Uploaded ./data/features/train/train_round_3.csv, 2 files out of an estimated total of 6\n",
      "Uploaded ./data/features/train/train_round_6.csv, 3 files out of an estimated total of 6\n",
      "Uploaded ./data/features/train/train_round_2.csv, 4 files out of an estimated total of 6\n",
      "Uploaded ./data/features/train/train_round_4.csv, 5 files out of an estimated total of 6\n",
      "Uploaded ./data/features/train/train_round_5.csv, 6 files out of an estimated total of 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_229fc20c559646f08551875da8fb29f6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_on_datastore = 'data'\n",
    "ds.upload(src_dir='./data/features/train', target_path=path_on_datastore, overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$AZUREML_DATAREFERENCE_5b3ca2f04f09428d976a5c17de811623\n"
     ]
    }
   ],
   "source": [
    "# Get data reference object for the data path\n",
    "ds_data = ds.path(path_on_datastore)\n",
    "print(ds_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--path': ds_data.as_mount(),\n",
    "    '--cv_path': './',\n",
    "    '--n_hidden_1': 5, \n",
    "    '--n_hidden_2': 5,\n",
    "    '--iter_max': 3,\n",
    "    '--penalty': 0\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='aml_estimator.py',\n",
    "                environment_definition=env)\n",
    "# The above estimator defined using environment_definition has problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--path': ds_data.as_mount(),\n",
    "    '--cv_path': './',\n",
    "    '--n_hidden_1': 5, \n",
    "    '--n_hidden_2': 5,\n",
    "    '--iter_max': 3,\n",
    "    '--penalty': 0\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='aml_estimator.py',\n",
    "                conda_packages=['pandas', 'r-base', 'r-data.table', 'r-rjson', 'r-doparallel'],\n",
    "                pip_packages=['azure-cli-core<2.0.55'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit job to Batch AI cluster\n",
    "run_batchai = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'tune_qrnn_1547986964549',\n",
       " 'target': 'cpucompute',\n",
       " 'status': 'Running',\n",
       " 'startTimeUtc': '2019-01-20T12:30:57.444364Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': '857cee45-9475-4124-87d7-2483f6c7716f'},\n",
       " 'runDefinition': {'Script': 'aml_estimator.py',\n",
       "  'Arguments': ['--path',\n",
       "   '$AZUREML_DATAREFERENCE_dced8724e0954ff78a554a6145adca80',\n",
       "   '--cv_path',\n",
       "   './',\n",
       "   '--n_hidden_1',\n",
       "   '5',\n",
       "   '--n_hidden_2',\n",
       "   '5',\n",
       "   '--iter_max',\n",
       "   '3',\n",
       "   '--penalty',\n",
       "   '0'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'cpucompute',\n",
       "  'DataReferences': {'dced8724e0954ff78a554a6145adca80': {'DataStoreName': 'workspaceblobstore',\n",
       "    'Mode': 'Mount',\n",
       "    'PathOnDataStore': 'data',\n",
       "    'PathOnCompute': None,\n",
       "    'Overwrite': False}},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults', 'azure-cli-core<2.0.55']},\n",
       "      'pandas',\n",
       "      'r-base',\n",
       "      'r-data.table',\n",
       "      'r-rjson',\n",
       "      'r-doparallel']}},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'ShmSize': '1g',\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://tsperfwszhouf2444925548.blob.core.windows.net/azureml/ExperimentRun/dcid.tune_qrnn_1547986964549/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=Ct2MTgwwZoqLEhUdMkm9bmS0tN72UkTpvU8YtlotZF8%3D&st=2019-01-20T12%3A39%3A59Z&se=2019-01-20T20%3A49%3A59Z&sp=r',\n",
       "  'azureml-logs/60_control_log.txt': 'https://tsperfwszhouf2444925548.blob.core.windows.net/azureml/ExperimentRun/dcid.tune_qrnn_1547986964549/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=z57XtWCoXNSeZXMpWbCYBixJKcisKbxUwS821ngDSv8%3D&st=2019-01-20T12%3A39%3A59Z&se=2019-01-20T20%3A49%3A59Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://tsperfwszhouf2444925548.blob.core.windows.net/azureml/ExperimentRun/dcid.tune_qrnn_1547986964549/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=WJNIMXmXM5jV1qGcHTvFLI5OPHK6mrvw3IEBpEo0Qjw%3D&st=2019-01-20T12%3A39%3A59Z&se=2019-01-20T20%3A49%3A59Z&sp=r'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load job and get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "run_batchai = Run(exp, \"tune_qrnn_1547986964549\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 82.9833541445754}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Hyperparameters using HyperDrive\n",
    "\n",
    "To tune hyperparameters using HyperDrive, we can use the compute target, docker environment, datastore and estimator that has been defined and created as above and additionally specify a parameter sampling technique, and then let the program run across the parameter sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--path': ds_data.as_mount(),\n",
    "    '--cv_path': './',\n",
    "    '--n_hidden_1': 5, \n",
    "    '--n_hidden_2': 5,\n",
    "    '--iter_max': 3,\n",
    "    '--penalty': 0\n",
    "}\n",
    "\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='aml_estimator.py',\n",
    "                environment_definition=env)\n",
    "\n",
    "ps = GridParameterSampling({\n",
    "    '--n_hidden_1': choice(4, 8), \n",
    "    '--n_hidden_2': choice(4, 8),\n",
    "    '--iter_max': choice(1, 2, 4, 6, 8, 10),\n",
    "    '--penalty': choice(0, 0.001),\n",
    "})\n",
    "\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='average pinball loss', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=48,\n",
    "                          max_concurrent_runs=16)\n",
    "# The above estimator has problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--path': ds_data.as_mount(),\n",
    "    '--cv_path': './',\n",
    "    '--n_hidden_1': 5, \n",
    "    '--n_hidden_2': 5,\n",
    "    '--iter_max': 3,\n",
    "    '--penalty': 0\n",
    "}\n",
    "\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='aml_estimator.py',\n",
    "                conda_packages=['pandas', 'r-base', 'r-data.table', 'r-rjson', 'r-doparallel'],\n",
    "                pip_packages=['azure-cli-core<2.0.55'])\n",
    "\n",
    "ps = GridParameterSampling({\n",
    "    '--n_hidden_1': choice(4, 8), \n",
    "    '--n_hidden_2': choice(2, 4, 8),\n",
    "    '--iter_max': choice(1, 2, 4, 6, 8),\n",
    "    '--penalty': choice(0, 0.001),\n",
    "})\n",
    "\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='average pinball loss', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=60,\n",
    "                          max_concurrent_runs=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The same input parameter(s) are specified in estimator script params and HyperDrive parameter space. HyperDrive parameter space definition will override duplicate entries in estimator. ['--n_hidden_1', '--n_hidden_2', '--iter_max', '--penalty'] is the list of overridden parameter(s).\n"
     ]
    }
   ],
   "source": [
    "htr = exp.submit(config=htc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RunDetails(htr).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'tune_qrnn_1548046929030',\n",
       " 'target': 'cpucompute',\n",
       " 'status': 'Running',\n",
       " 'properties': {'primary_metric_config': '{\"name\": \"average pinball loss\", \"goal\": \"minimize\"}',\n",
       "  'runTemplate': 'HyperDrive',\n",
       "  'azureml.runsource': 'hyperdrive'},\n",
       " 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://tsperfwszhouf2444925548.blob.core.windows.net/azureml/ExperimentRun/dcid.tune_qrnn_1548046929030/azureml-logs/hyperdrive.txt?sv=2018-03-28&sr=b&sig=y1zqo7nOQm%2BtYiraIq0Jd9blTlhdp7gzsay106bHN6A%3D&st=2019-01-21T05%3A02%3A46Z&se=2019-01-21T13%3A12%3A46Z&sp=r'}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htr.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load job and get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Run\n",
    "htr = Run(exp, \"tune_qrnn_1548046929030\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = htr.get_best_run_by_primary_metric()\n",
    "best_parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "print(best_parameter_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = htr.get_children()\n",
    "\n",
    "results_dict = {'pinball_loss': [], 'n_hidden_1': [], 'n_hidden_2': [], 'iter_max': [], 'penalty': []} \n",
    "for child_run in results:\n",
    "    if child_run.get_status() == \"Completed\":\n",
    "        arguments = child_run.get_details()['runDefinition']['Arguments']\n",
    "        results_dict['pinball_loss'].append(child_run.get_metrics()['average pinball loss'])\n",
    "        results_dict['n_hidden_1'].append(int(arguments[5]))\n",
    "        results_dict['n_hidden_2'].append(int(arguments[7]))\n",
    "        results_dict['iter_max'].append(int(arguments[9]))\n",
    "        results_dict['penalty'].append(float(arguments[11]))\n",
    "\n",
    "results_df = pd.DataFrame.from_dict(results_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tsperf]",
   "language": "python",
   "name": "conda-env-tsperf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
