{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\honglu\\OneDrive - Microsoft\\Projects\\ForecastBenchmark\\code\\TSPerf\\energy_load\\GEFCom2017_D_Prob_MT_hourly\\submissions\\fnn\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name = 'tsbacktest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "run_config_user_managed.environment.python.interpreter_path = 'C:/Users/honglu/AppData/Local/conda/conda/envs/amlsdk/python.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory='./', \n",
    "                      script='aml_estimator.py', \n",
    "                      arguments=['--n_hidden_1', '5',\n",
    "                                 '--n_hidden_2', '5',\n",
    "                                 '--iter_max', '3',\n",
    "                                 '--penalty', '0',\n",
    "                                 '--path', './data/'],\n",
    "                      run_config=run_config_user_managed)\n",
    "run_local = exp.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'tsbacktest_1547507062_ee88896c',\n",
       " 'target': 'local',\n",
       " 'status': 'Failed',\n",
       " 'startTimeUtc': '2019-01-14T23:04:26.173053Z',\n",
       " 'endTimeUtc': '2019-01-14T23:04:36.293174Z',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'e4d4f433-e3d3-4593-bc25-9f33e06b3cc8'},\n",
       " 'runDefinition': {'Script': 'aml_estimator.py',\n",
       "  'Arguments': ['--n_hidden_1',\n",
       "   '5',\n",
       "   '--n_hidden_2',\n",
       "   '5',\n",
       "   '--iter_max',\n",
       "   '3',\n",
       "   '--penalty',\n",
       "   '0',\n",
       "   '--path',\n",
       "   './data/'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'local',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'C:/Users/honglu/AppData/Local/conda/conda/envs/amlsdk/python.exe',\n",
       "    'UserManagedDependencies': True,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults']}]},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.1',\n",
       "    'Enabled': False,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1547507062_ee88896c/azureml-logs/60_control_log.txt?sv=2018-03-28&sr=b&sig=NuOEFgdzhxqRFtWFRzi5R8H8uGiQm1faM1JeaLOQew0%3D&st=2019-01-14T22%3A54%3A55Z&se=2019-01-15T07%3A04%3A55Z&sp=r',\n",
       "  'azureml-logs/80_driver_log.txt': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1547507062_ee88896c/azureml-logs/80_driver_log.txt?sv=2018-03-28&sr=b&sig=m0UENd4sPYGGCNy0VjPYzgAU1rx7quocWs9Vm0aCo8I%3D&st=2019-01-14T22%3A54%3A55Z&se=2019-01-15T07%3A04%3A55Z&sp=r',\n",
       "  'azureml-logs/azureml.log': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1547507062_ee88896c/azureml-logs/azureml.log?sv=2018-03-28&sr=b&sig=%2FJnngox9Up3Xy3Rm2yHVpFQLyZU9YhYJ0TlgrKkTyI0%3D&st=2019-01-14T22%3A54%3A55Z&se=2019-01-15T07%3A04%3A55Z&sp=r'}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_local.get_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. hlutsperfnn\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name =  \"hlutsperfnn\"\n",
    "compute_min_nodes = 0\n",
    "compute_max_nodes = 16\n",
    "\n",
    "vm_size = \"STANDARD_D3_V2\"\n",
    "\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'r-base', 'r-data.table', 'r-rjson', 'r-optparse'],\n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--n_hidden_1': 5, \n",
    "    '--n_hidden_2': 5,\n",
    "    '--iter_max': 3,\n",
    "    '--penalty': 0,\n",
    "    '--path': ws.get_default_datastore().as_mount()\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='aml_estimator.py',\n",
    "                environment_definition=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_batchai = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'tsbacktest_1547498734823',\n",
       " 'target': 'hlutsperfnn',\n",
       " 'status': 'Preparing',\n",
       " 'properties': {'azureml.runsource': 'experiment',\n",
       "  'ContentSnapshotId': 'ed0ee6ca-b784-4e5d-9ef1-ca927152fc58'},\n",
       " 'runDefinition': {'Script': 'aml_estimator.py',\n",
       "  'Arguments': ['--param', '2'],\n",
       "  'SourceDirectoryDataStore': None,\n",
       "  'Framework': 0,\n",
       "  'Communicator': 0,\n",
       "  'Target': 'hlutsperfnn',\n",
       "  'DataReferences': {},\n",
       "  'JobName': None,\n",
       "  'AutoPrepareEnvironment': True,\n",
       "  'MaxRunDurationSeconds': None,\n",
       "  'NodeCount': 1,\n",
       "  'Environment': {'Python': {'InterpreterPath': 'python',\n",
       "    'UserManagedDependencies': False,\n",
       "    'CondaDependencies': {'name': 'project_environment',\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults==1.0.8']},\n",
       "      'r-base',\n",
       "      'r-data.table'],\n",
       "     'channels': ['r']},\n",
       "    'CondaDependenciesFile': None},\n",
       "   'EnvironmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n",
       "   'Docker': {'BaseImage': 'mcr.microsoft.com/azureml/base:0.2.1',\n",
       "    'Enabled': True,\n",
       "    'SharedVolumes': True,\n",
       "    'Preparation': None,\n",
       "    'GpuSupport': False,\n",
       "    'Arguments': [],\n",
       "    'BaseImageRegistry': {'Address': None,\n",
       "     'Username': None,\n",
       "     'Password': None}},\n",
       "   'Spark': {'Repositories': ['https://mmlspark.azureedge.net/maven'],\n",
       "    'Packages': [{'Group': 'com.microsoft.ml.spark',\n",
       "      'Artifact': 'mmlspark_2.11',\n",
       "      'Version': '0.12'}],\n",
       "    'PrecachePackages': True}},\n",
       "  'History': {'OutputCollection': True},\n",
       "  'Spark': {'Configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'BatchAi': {'NodeCount': 0},\n",
       "  'AmlCompute': {'Name': None,\n",
       "   'VmSize': None,\n",
       "   'VmPriority': None,\n",
       "   'RetainCluster': False,\n",
       "   'ClusterMaxNodeCount': 1},\n",
       "  'Tensorflow': {'WorkerCount': 1, 'ParameterServerCount': 1},\n",
       "  'Mpi': {'ProcessCountPerNode': 1},\n",
       "  'Hdi': {'YarnDeployMode': 2},\n",
       "  'ContainerInstance': {'Region': None, 'CpuCores': 0, 'MemoryGb': 0},\n",
       "  'ExposedPorts': None,\n",
       "  'PrepareEnvironment': None},\n",
       " 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://hluamlwsnew7391587880.blob.core.windows.net/azureml/ExperimentRun/tsbacktest_1547498734823/azureml-logs/20_image_build_log.txt?sv=2018-03-28&sr=b&sig=YVhCfpWdvjth0w6L%2FlMndR1E6S%2BBCL8bfr1X4TN6Xdk%3D&st=2019-01-14T20%3A39%3A48Z&se=2019-01-15T04%3A49%3A48Z&sp=r'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_details()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amlsdk",
   "language": "python",
   "name": "amlsdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
