{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Backtesting using HyperDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "In order to run this notebook, you need to install AML SDK and its widget extension in your environment by running the following commands in commandline or terminal.  \n",
    "First, you need to activate your environment by running `activate <your env>` or `source activate <your env>`(on Linux).   \n",
    "`pip install --upgrade azureml-sdk[notebooks,automl]`  \n",
    "`jupyter nbextension install --py --user azureml.train.widgets`  \n",
    "`jupyter nbextension enable --py --user azureml.train.widgets`\n",
    "\n",
    "To add the environment to your Jupyter kernels, you can do `python3 -m ipykernel install --name <your env>`. Besides, you need to create an Azure ML workspace and download its configuration file (`config.json`) by following the [configuration.ipynb](https://github.com/Azure/MachineLearningNotebooks/blob/master/configuration.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up workspace and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: C:\\Users\\hlu\\TSPerf\\prototypes\\cross_validation\\config.json\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "ws = Workspace.from_config()\n",
    "exp = Experiment(workspace=ws, name = 'tsbacktest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate script locally\n",
    "Configure local, user managed environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "run_config_user_managed = RunConfiguration()\n",
    "run_config_user_managed.environment.python.user_managed_dependencies = True\n",
    "run_config_user_managed.environment.python.interpreter_path = 'C:/Anaconda/envs/tsperf/python.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory='./', \n",
    "                      script='train_validation.py', \n",
    "                      arguments=['--data-folder', 'C:/Users/hlu/TSPerf/prototypes/cross_validation/data/', '--n-estimators', '10', '--min-samples-split', '10'],\n",
    "                      run_config=run_config_user_managed)\n",
    "run_local = exp.submit(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 193.81733289262013}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_local.get_details()\n",
    "run_local.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a single job to BatchAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Batch AI cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target hlutsperfnew, just use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, BatchAiCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "batchai_cluster_name = \"hlutsperfnew\"\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name = batchai_cluster_name)\n",
    "    if type(compute_target) is BatchAiCompute:\n",
    "        print('found compute target {}, just use it.'.format(batchai_cluster_name))\n",
    "    else:\n",
    "        print('{} exists but it is not a Batch AI cluster. Please choose a different name.'.format(batchai_cluster_name))\n",
    "except ComputeTargetException:\n",
    "    print('creating a new compute target...')\n",
    "    compute_config = BatchAiCompute.provisioning_configuration(vm_size=\"STANDARD_D2_V2\",\n",
    "                                                                autoscale_enabled=True,\n",
    "                                                                cluster_min_nodes=0, \n",
    "                                                                cluster_max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, batchai_cluster_name, compute_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it uses the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "    # Use the 'status' property to get a detailed status for the current cluster. \n",
    "    print(compute_target.status.serialize()) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Docker environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "env = EnvironmentDefinition()\n",
    "\n",
    "env.python.user_managed_dependencies = False\n",
    "env.python.conda_dependencies = CondaDependencies.create(conda_packages=['pandas', 'numpy', 'scikit-garden', 'joblib'],\n",
    "                                                         python_version='3.6.2')\n",
    "env.python.conda_dependencies.add_channel('conda-forge')\n",
    "env.docker.enabled=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import EnvironmentDefinition\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_folder = './'\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ws.get_default_datastore().as_mount(),\n",
    "    '--n-estimators': 10,\n",
    "    '--min-samples-split': 10\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                use_docker=True,\n",
    "                entry_script='train_validation.py',\n",
    "                environment_definition=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "run_batchai = exp.submit(config=est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run_batchai).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average pinball loss': 193.81733289262013}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_batchai.get_details()\n",
    "run_batchai.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune hyper parameter using HyperDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "ps = RandomParameterSampling({\n",
    "    '--min-samples-split': choice(5, 10),\n",
    "    '--n-estimators': choice(10, 100)\n",
    "})\n",
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps, \n",
    "                          primary_metric_name='average pinball loss', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MINIMIZE, \n",
    "                          max_total_runs=8,\n",
    "                          max_concurrent_runs=4)\n",
    "htr = exp.submit(config=htc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(htr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--data-folder', '$AZUREML_DATAREFERENCE_workspacefilestore', '--min-samples-split', '5', '--n-estimators', '10']\n"
     ]
    }
   ],
   "source": [
    "best_run = htr.get_best_run_by_primary_metric()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "print(parameter_values)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
